PS C:\MyLab\UIUC\Research\JNER\src> python .\CALGAT2.py
PyTorch version: 2.6.0+cpu
PyTorch Geometric version: 2.6.1
Device: cpu
Using Covariance Node Features
Loading data from: C:\MyLab\UIUC\Research\JNER\preprocessed\fcm
Using Covariance Node Features. Input feature dimension inferred as: 64
Data object __dict__ in prepare_graph_data with covariance features: {'_edge_attr_cls': <class 'torch_geometric.data.data.DataEdgeAttr'>, '_tensor_attr_cls': <class 'torch_geometric.data.data.DataTensorAttr'>, '_store': {'x': tensor([[0.0000, 0.1266, 0.0562,  ..., 0.2353, 0.1585, 0.2156],
        [0.1266, 0.0000, 0.1935,  ..., 0.1008, 0.1533, 0.0554],
        [0.0562, 0.1935, 0.0000,  ..., 0.1106, 0.1683, 0.0424],
        ...,
        [0.2353, 0.1008, 0.1106,  ..., 0.0000, 0.1579, 0.0847],
        [0.1585, 0.1533, 0.1683,  ..., 0.1579, 0.0000, 0.0953],
        [0.2156, 0.0554, 0.0424,  ..., 0.0847, 0.0953, 0.0000]]), 'edge_index': tensor([[ 0,  0,  0,  ..., 63, 63, 63],
        [ 1,  2,  3,  ..., 60, 61, 62]]), 'edge_attr': tensor([0.1305, 0.0502, 0.4495,  ..., 0.2149, 0.1384, 0.2336])}}
Data object __dict__ in prepare_graph_data with covariance features: {'_edge_attr_cls': <class 'torch_geometric.data.data.DataEdgeAttr'>, '_tensor_attr_cls': <class 'torch_geometric.data.data.DataTensorAttr'>, '_store': {'x': tensor([[ 0.0000, -0.0270, -0.1391,  ...,  0.5842,  0.1437,  0.3564],
        [-0.0270,  0.0000,  0.1371,  ...,  0.0116,  0.0090, -0.0123],
        [-0.1391,  0.1371,  0.0000,  ..., -0.0651,  0.1327, -0.0272],
        ...,
        [ 0.5842,  0.0116, -0.0651,  ...,  0.0000,  0.2151,  0.2879],
        [ 0.1437,  0.0090,  0.1327,  ...,  0.2151,  0.0000,  0.1527],
        [ 0.3564, -0.0123, -0.0272,  ...,  0.2879,  0.1527,  0.0000]]), 'edge_index': tensor([[ 0,  0,  0,  ..., 63, 63, 63],
        [ 3,  5,  6,  ..., 60, 61, 62]]), 'edge_attr': tensor([0.1617, 0.6791, 0.0263,  ..., 0.2140, 0.4324, 0.1804])}}
Data object __dict__ in prepare_graph_data with covariance features: {'_edge_attr_cls': <class 'torch_geometric.data.data.DataEdgeAttr'>, '_tensor_attr_cls': <class 'torch_geometric.data.data.DataTensorAttr'>, '_store': {'x': tensor([[ 0.0000, -0.1210, -0.0760,  ...,  0.3553, -0.1726,  0.2244],
        [-0.1210,  0.0000,  0.0334,  ..., -0.1064,  0.0365, -0.0261],
        [-0.0760,  0.0334,  0.0000,  ..., -0.0503,  0.2164,  0.0429],
        ...,
        [ 0.3553, -0.1064, -0.0503,  ...,  0.0000, -0.0966,  0.1302],
        [-0.1726,  0.0365,  0.2164,  ..., -0.0966,  0.0000,  0.0410],
        [ 0.2244, -0.0261,  0.0429,  ...,  0.1302,  0.0410,  0.0000]]), 'edge_index': tensor([[ 0,  0,  0,  ..., 63, 63, 63],
        [ 3,  4,  6,  ..., 60, 61, 62]]), 'edge_attr': tensor([0.7199, 0.5673, 0.3833,  ..., 0.0879, 0.2132, 0.0166])}}
Data object __dict__ in prepare_graph_data with covariance features: {'_edge_attr_cls': <class 'torch_geometric.data.data.DataEdgeAttr'>, '_tensor_attr_cls': <class 'torch_geometric.data.data.DataTensorAttr'>, '_store': {'x': tensor([[ 0.0000,  0.0894,  0.0059,  ...,  0.0705,  0.0514,  0.0098],
        [ 0.0894,  0.0000,  0.2715,  ...,  0.1323,  0.0875,  0.0601],
        [ 0.0059,  0.2715,  0.0000,  ...,  0.0860, -0.1234,  0.1159],
        ...,
        [ 0.0705,  0.1323,  0.0860,  ...,  0.0000,  0.0410,  0.0377],
        [ 0.0514,  0.0875, -0.1234,  ...,  0.0410,  0.0000, -0.0928],
        [ 0.0098,  0.0601,  0.1159,  ...,  0.0377, -0.0928,  0.0000]]), 'edge_index': tensor([[ 0,  0,  0,  ..., 63, 63, 63],
        [ 1,  3,  4,  ..., 57, 59, 61]]), 'edge_attr': tensor([0.1725, 0.5270, 0.2271,  ..., 0.2488, 0.2255, 0.1600])}}
Data object __dict__ in prepare_graph_data with covariance features: {'_edge_attr_cls': <class 'torch_geometric.data.data.DataEdgeAttr'>, '_tensor_attr_cls': <class 'torch_geometric.data.data.DataTensorAttr'>, '_store': {'x': tensor([[ 0.0000e+00,  7.8801e-02,  1.0224e-01,  ...,  4.7608e-01,
         -5.8846e-05,  1.3693e-01],
        [ 7.8801e-02,  0.0000e+00,  2.2024e-01,  ...,  4.3480e-02,
          4.5782e-02,  6.0967e-02],
        [ 1.0224e-01,  2.2024e-01,  0.0000e+00,  ...,  9.3468e-03,
          2.0609e-01,  1.5329e-01],
        ...,
        [ 4.7608e-01,  4.3480e-02,  9.3468e-03,  ...,  0.0000e+00,
         -4.1860e-02,  9.9360e-02],
        [-5.8846e-05,  4.5782e-02,  2.0609e-01,  ..., -4.1860e-02,
          0.0000e+00,  5.7784e-02],
        [ 1.3693e-01,  6.0967e-02,  1.5329e-01,  ...,  9.9360e-02,
          5.7784e-02,  0.0000e+00]]), 'edge_index': tensor([[ 0,  0,  0,  ..., 63, 63, 63],
        [ 1,  2,  3,  ..., 60, 61, 62]]), 'edge_attr': tensor([0.0740, 0.0855, 0.5977,  ..., 0.3491, 0.2262, 0.0348])}}
Data object __dict__ in prepare_graph_data with covariance features: {'_edge_attr_cls': <class 'torch_geometric.data.data.DataEdgeAttr'>, '_tensor_attr_cls': <class 'torch_geometric.data.data.DataTensorAttr'>, '_store': {'x': tensor([[ 0.0000e+00, -3.4461e-03,  8.9729e-02,  ...,  4.7630e-01,
          9.5639e-02,  1.9355e-01],
        [-3.4461e-03,  0.0000e+00,  2.8990e-01,  ..., -1.3439e-01,
          2.7635e-01,  1.4231e-01],
        [ 8.9729e-02,  2.8990e-01,  0.0000e+00,  ..., -1.1917e-02,
          2.2515e-01,  1.5006e-01],
        ...,
        [ 4.7630e-01, -1.3439e-01, -1.1917e-02,  ...,  0.0000e+00,
          4.7599e-04,  1.5851e-01],
        [ 9.5639e-02,  2.7635e-01,  2.2515e-01,  ...,  4.7599e-04,
          0.0000e+00,  2.5326e-01],
        [ 1.9355e-01,  1.4231e-01,  1.5006e-01,  ...,  1.5851e-01,
          2.5326e-01,  0.0000e+00]]), 'edge_index': tensor([[ 0,  0,  0,  ..., 63, 63, 63],
        [ 2,  3,  4,  ..., 60, 61, 62]]), 'edge_attr': tensor([0.0688, 0.6373, 0.0638,  ..., 0.2897, 0.3295, 0.4215])}}
Data object __dict__ in prepare_graph_data with covariance features: {'_edge_attr_cls': <class 'torch_geometric.data.data.DataEdgeAttr'>, '_tensor_attr_cls': <class 'torch_geometric.data.data.DataTensorAttr'>, '_store': {'x': tensor([[0.0000, 0.0231, 0.0701,  ..., 0.2830, 0.0123, 0.1304],
        [0.0231, 0.0000, 0.1104,  ..., 0.0527, 0.1480, 0.0862],
        [0.0701, 0.1104, 0.0000,  ..., 0.1155, 0.3902, 0.1608],
        ...,
        [0.2830, 0.0527, 0.1155,  ..., 0.0000, 0.0445, 0.1542],
        [0.0123, 0.1480, 0.3902,  ..., 0.0445, 0.0000, 0.1509],
        [0.1304, 0.0862, 0.1608,  ..., 0.1542, 0.1509, 0.0000]]), 'edge_index': tensor([[ 0,  0,  0,  ..., 63, 63, 63],
        [ 2,  3,  4,  ..., 60, 61, 62]]), 'edge_attr': tensor([0.0202, 0.5059, 0.4020,  ..., 0.3112, 0.3282, 0.1288])}}
Data object __dict__ in prepare_graph_data with covariance features: {'_edge_attr_cls': <class 'torch_geometric.data.data.DataEdgeAttr'>, '_tensor_attr_cls': <class 'torch_geometric.data.data.DataTensorAttr'>, '_store': {'x': tensor([[0.0000, 0.0772, 0.1338,  ..., 0.2838, 0.0507, 0.1141],
        [0.0772, 0.0000, 0.2853,  ..., 0.1021, 0.1873, 0.2045],
        [0.1338, 0.2853, 0.0000,  ..., 0.1673, 0.1724, 0.2808],
        ...,
        [0.2838, 0.1021, 0.1673,  ..., 0.0000, 0.0705, 0.1412],
        [0.0507, 0.1873, 0.1724,  ..., 0.0705, 0.0000, 0.1744],
        [0.1141, 0.2045, 0.2808,  ..., 0.1412, 0.1744, 0.0000]]), 'edge_index': tensor([[ 0,  0,  0,  ..., 63, 63, 63],
        [ 1,  2,  3,  ..., 60, 61, 62]]), 'edge_attr': tensor([0.0300, 0.2643, 0.4971,  ..., 0.3012, 0.2013, 0.2498])}}
Data object __dict__ in prepare_graph_data with covariance features: {'_edge_attr_cls': <class 'torch_geometric.data.data.DataEdgeAttr'>, '_tensor_attr_cls': <class 'torch_geometric.data.data.DataTensorAttr'>, '_store': {'x': tensor([[0.0000, 0.1099, 0.0634,  ..., 0.3906, 0.0724, 0.2358],
        [0.1099, 0.0000, 0.0578,  ..., 0.1379, 0.1437, 0.0991],
        [0.0634, 0.0578, 0.0000,  ..., 0.1063, 0.0086, 0.0240],
        ...,
        [0.3906, 0.1379, 0.1063,  ..., 0.0000, 0.0255, 0.1652],
        [0.0724, 0.1437, 0.0086,  ..., 0.0255, 0.0000, 0.1986],
        [0.2358, 0.0991, 0.0240,  ..., 0.1652, 0.1986, 0.0000]]), 'edge_index': tensor([[ 0,  0,  0,  ..., 63, 63, 63],
        [ 1,  2,  3,  ..., 60, 61, 62]]), 'edge_attr': tensor([0.0772, 0.0813, 0.2880,  ..., 0.0900, 0.1902, 0.2297])}}
Data object __dict__ in prepare_graph_data with covariance features: {'_edge_attr_cls': <class 'torch_geometric.data.data.DataEdgeAttr'>, '_tensor_attr_cls': <class 'torch_geometric.data.data.DataTensorAttr'>, '_store': {'x': tensor([[ 0.0000, -0.2742, -0.0713,  ...,  0.5032,  0.1569,  0.2634],
        [-0.2742,  0.0000,  0.3504,  ..., -0.2378, -0.0904, -0.1422],
        [-0.0713,  0.3504,  0.0000,  ..., -0.0606,  0.0742,  0.0136],
        ...,
        [ 0.5032, -0.2378, -0.0606,  ...,  0.0000,  0.0494,  0.1598],
        [ 0.1569, -0.0904,  0.0742,  ...,  0.0494,  0.0000,  0.2707],
        [ 0.2634, -0.1422,  0.0136,  ...,  0.1598,  0.2707,  0.0000]]), 'edge_index': tensor([[ 0,  0,  0,  ..., 63, 63, 63],
        [ 3,  5,  6,  ..., 60, 61, 62]]), 'edge_attr': tensor([0.0481, 0.5905, 0.5798,  ..., 0.3258, 0.2269, 0.4245])}}
Data object __dict__ in prepare_graph_data with covariance features: {'_edge_attr_cls': <class 'torch_geometric.data.data.DataEdgeAttr'>, '_tensor_attr_cls': <class 'torch_geometric.data.data.DataTensorAttr'>, '_store': {'x': tensor([[ 0.0000, -0.0424, -0.0926,  ...,  0.4659,  0.2129,  0.2967],
        [-0.0424,  0.0000,  0.2987,  ..., -0.0377,  0.0367, -0.0012],
        [-0.0926,  0.2987,  0.0000,  ..., -0.0906, -0.0019, -0.0279],
        ...,
        [ 0.4659, -0.0377, -0.0906,  ...,  0.0000,  0.2985,  0.4043],
        [ 0.2129,  0.0367, -0.0019,  ...,  0.2985,  0.0000,  0.3516],
        [ 0.2967, -0.0012, -0.0279,  ...,  0.4043,  0.3516,  0.0000]]), 'edge_index': tensor([[ 0,  0,  0,  ..., 63, 63, 63],
        [ 3,  4,  5,  ..., 60, 61, 62]]), 'edge_attr': tensor([0.3598, 0.0138, 0.3910,  ..., 0.4417, 0.5550, 0.4212])}}
Data object __dict__ in prepare_graph_data with covariance features: {'_edge_attr_cls': <class 'torch_geometric.data.data.DataEdgeAttr'>, '_tensor_attr_cls': <class 'torch_geometric.data.data.DataTensorAttr'>, '_store': {'x': tensor([[ 0.0000e+00, -8.6305e-04,  2.0805e-02,  ...,  3.9790e-01,
         -1.9340e-02,  5.1745e-03],
        [-8.6305e-04,  0.0000e+00,  5.4508e-03,  ...,  2.4547e-03,
          2.9547e-02,  3.3906e-03],
        [ 2.0805e-02,  5.4508e-03,  0.0000e+00,  ...,  2.8428e-02,
         -3.7738e-04, -1.0716e-02],
        ...,
        [ 3.9790e-01,  2.4547e-03,  2.8428e-02,  ...,  0.0000e+00,
          8.9256e-03,  3.0998e-03],
        [-1.9340e-02,  2.9547e-02, -3.7738e-04,  ...,  8.9256e-03,
          0.0000e+00,  8.2956e-03],
        [ 5.1745e-03,  3.3906e-03, -1.0716e-02,  ...,  3.0998e-03,
          8.2956e-03,  0.0000e+00]]), 'edge_index': tensor([[ 0,  0,  0,  ..., 63, 63, 63],
        [ 1,  3,  4,  ..., 60, 61, 62]]), 'edge_attr': tensor([0.0026, 0.4154, 0.0514,  ..., 0.0188, 0.0550, 0.0451])}}
Data object __dict__ in prepare_graph_data with covariance features: {'_edge_attr_cls': <class 'torch_geometric.data.data.DataEdgeAttr'>, '_tensor_attr_cls': <class 'torch_geometric.data.data.DataTensorAttr'>, '_store': {'x': tensor([[0.0000, 0.1417, 0.1392,  ..., 0.3930, 0.1214, 0.2180],
        [0.1417, 0.0000, 0.2757,  ..., 0.1475, 0.1824, 0.1588],
        [0.1392, 0.2757, 0.0000,  ..., 0.1733, 0.2539, 0.2319],
        ...,
        [0.3930, 0.1475, 0.1733,  ..., 0.0000, 0.1481, 0.1667],
        [0.1214, 0.1824, 0.2539,  ..., 0.1481, 0.0000, 0.2027],
        [0.2180, 0.1588, 0.2319,  ..., 0.1667, 0.2027, 0.0000]]), 'edge_index': tensor([[ 0,  0,  0,  ..., 63, 63, 63],
        [ 1,  2,  3,  ..., 60, 61, 62]]), 'edge_attr': tensor([0.1415, 0.2044, 0.6818,  ..., 0.2769, 0.2938, 0.2705])}}
Data object __dict__ in prepare_graph_data with covariance features: {'_edge_attr_cls': <class 'torch_geometric.data.data.DataEdgeAttr'>, '_tensor_attr_cls': <class 'torch_geometric.data.data.DataTensorAttr'>, '_store': {'x': tensor([[ 0.0000e+00,  3.7392e-02,  8.8625e-05,  ...,  5.5720e-01,
         -1.6694e-01,  1.3675e-01],
        [ 3.7392e-02,  0.0000e+00,  7.5219e-02,  ...,  2.1364e-02,
          2.0840e-01,  3.0457e-02],
        [ 8.8625e-05,  7.5219e-02,  0.0000e+00,  ...,  3.5627e-02,
          1.2311e-01,  6.6924e-02],
        ...,
        [ 5.5720e-01,  2.1364e-02,  3.5627e-02,  ...,  0.0000e+00,
         -1.6237e-01,  1.2231e-01],
        [-1.6694e-01,  2.0840e-01,  1.2311e-01,  ..., -1.6237e-01,
          0.0000e+00, -1.0594e-02],
        [ 1.3675e-01,  3.0457e-02,  6.6924e-02,  ...,  1.2231e-01,
         -1.0594e-02,  0.0000e+00]]), 'edge_index': tensor([[ 0,  0,  0,  ..., 63, 63, 63],
        [ 1,  3,  4,  ..., 60, 61, 62]]), 'edge_attr': tensor([0.1194, 0.6938, 0.0509,  ..., 0.1790, 0.1918, 0.0325])}}
Data object __dict__ in prepare_graph_data with covariance features: {'_edge_attr_cls': <class 'torch_geometric.data.data.DataEdgeAttr'>, '_tensor_attr_cls': <class 'torch_geometric.data.data.DataTensorAttr'>, '_store': {'x': tensor([[0.0000, 0.1401, 0.2418,  ..., 0.5159, 0.2212, 0.3002],
        [0.1401, 0.0000, 0.1605,  ..., 0.1547, 0.1170, 0.1193],
        [0.2418, 0.1605, 0.0000,  ..., 0.2521, 0.2230, 0.2319],
        ...,
        [0.5159, 0.1547, 0.2521,  ..., 0.0000, 0.2237, 0.3057],
        [0.2212, 0.1170, 0.2230,  ..., 0.2237, 0.0000, 0.2193],
        [0.3002, 0.1193, 0.2319,  ..., 0.3057, 0.2193, 0.0000]]), 'edge_index': tensor([[ 0,  0,  0,  ..., 63, 63, 63],
        [ 1,  2,  3,  ..., 60, 61, 62]]), 'edge_attr': tensor([0.0435, 0.3707, 0.5588,  ..., 0.1232, 0.4554, 0.1998])}}
Data object __dict__ in prepare_graph_data with covariance features: {'_edge_attr_cls': <class 'torch_geometric.data.data.DataEdgeAttr'>, '_tensor_attr_cls': <class 'torch_geometric.data.data.DataTensorAttr'>, '_store': {'x': tensor([[ 0.0000,  0.1047,  0.1387,  ...,  0.5650,  0.1960,  0.2182],
        [ 0.1047,  0.0000,  0.1469,  ...,  0.1060,  0.1031,  0.0453],
        [ 0.1387,  0.1469,  0.0000,  ...,  0.1169,  0.2362, -0.0163],
        ...,
        [ 0.5650,  0.1060,  0.1169,  ...,  0.0000,  0.1716,  0.2746],
        [ 0.1960,  0.1031,  0.2362,  ...,  0.1716,  0.0000,  0.0127],
        [ 0.2182,  0.0453, -0.0163,  ...,  0.2746,  0.0127,  0.0000]]), 'edge_index': tensor([[ 0,  0,  0,  ..., 63, 63, 63],
        [ 1,  2,  3,  ..., 58, 60, 61]]), 'edge_attr': tensor([0.0240, 0.0345, 0.4797,  ..., 0.0039, 0.3356, 0.4436])}}
Data object __dict__ in prepare_graph_data with covariance features: {'_edge_attr_cls': <class 'torch_geometric.data.data.DataEdgeAttr'>, '_tensor_attr_cls': <class 'torch_geometric.data.data.DataTensorAttr'>, '_store': {'x': tensor([[ 0.0000, -0.0051,  0.0837,  ...,  0.1507, -0.0506,  0.0619],
        [-0.0051,  0.0000,  0.2935,  ...,  0.0799, -0.0478,  0.1941],
        [ 0.0837,  0.2935,  0.0000,  ...,  0.0919, -0.0963,  0.3035],
        ...,
        [ 0.1507,  0.0799,  0.0919,  ...,  0.0000,  0.0080,  0.1143],
        [-0.0506, -0.0478, -0.0963,  ...,  0.0080,  0.0000,  0.1024],
        [ 0.0619,  0.1941,  0.3035,  ...,  0.1143,  0.1024,  0.0000]]), 'edge_index': tensor([[ 0,  0,  0,  ..., 63, 63, 63],
        [ 2,  3,  4,  ..., 60, 61, 62]]), 'edge_attr': tensor([0.1614, 0.4763, 0.3149,  ..., 0.4163, 0.2902, 0.1646])}}
Data object __dict__ in prepare_graph_data with covariance features: {'_edge_attr_cls': <class 'torch_geometric.data.data.DataEdgeAttr'>, '_tensor_attr_cls': <class 'torch_geometric.data.data.DataTensorAttr'>, '_store': {'x': tensor([[ 0.0000, -0.0052,  0.0771,  ...,  0.1867,  0.0201,  0.2122],
        [-0.0052,  0.0000,  0.1806,  ...,  0.0280,  0.1952,  0.0924],
        [ 0.0771,  0.1806,  0.0000,  ...,  0.0286,  0.1395,  0.0985],
        ...,
        [ 0.1867,  0.0280,  0.0286,  ...,  0.0000,  0.0873,  0.1890],
        [ 0.0201,  0.1952,  0.1395,  ...,  0.0873,  0.0000,  0.2017],
        [ 0.2122,  0.0924,  0.0985,  ...,  0.1890,  0.2017,  0.0000]]), 'edge_index': tensor([[ 0,  0,  0,  ..., 63, 63, 63],
        [ 2,  3,  4,  ..., 60, 61, 62]]), 'edge_attr': tensor([0.2014, 0.4244, 0.0096,  ..., 0.1886, 0.3448, 0.3532])}}
Data object __dict__ in prepare_graph_data with covariance features: {'_edge_attr_cls': <class 'torch_geometric.data.data.DataEdgeAttr'>, '_tensor_attr_cls': <class 'torch_geometric.data.data.DataTensorAttr'>, '_store': {'x': tensor([[ 0.0000,  0.0438, -0.0791,  ...,  0.2550,  0.0339,  0.0797],
        [ 0.0438,  0.0000,  0.0175,  ...,  0.0321,  0.0696,  0.0331],
        [-0.0791,  0.0175,  0.0000,  ..., -0.1699, -0.0183, -0.0416],
        ...,
        [ 0.2550,  0.0321, -0.1699,  ...,  0.0000,  0.0798,  0.1588],
        [ 0.0339,  0.0696, -0.0183,  ...,  0.0798,  0.0000,  0.0935],
        [ 0.0797,  0.0331, -0.0416,  ...,  0.1588,  0.0935,  0.0000]]), 'edge_index': tensor([[ 0,  0,  0,  ..., 63, 63, 63],
        [ 3,  4,  6,  ..., 60, 61, 62]]), 'edge_attr': tensor([0.3762, 0.0035, 0.0397,  ..., 0.3857, 0.3154, 0.2695])}}
Data object __dict__ in prepare_graph_data with covariance features: {'_edge_attr_cls': <class 'torch_geometric.data.data.DataEdgeAttr'>, '_tensor_attr_cls': <class 'torch_geometric.data.data.DataTensorAttr'>, '_store': {'x': tensor([[ 0.0000, -0.2003, -0.0125,  ...,  0.3382, -0.1028,  0.0922],
        [-0.2003,  0.0000,  0.1608,  ..., -0.1664,  0.1147, -0.0429],
        [-0.0125,  0.1608,  0.0000,  ...,  0.0086, -0.1084,  0.1271],
        ...,
        [ 0.3382, -0.1664,  0.0086,  ...,  0.0000, -0.0596,  0.1394],
        [-0.1028,  0.1147, -0.1084,  ..., -0.0596,  0.0000,  0.0833],
        [ 0.0922, -0.0429,  0.1271,  ...,  0.1394,  0.0833,  0.0000]]), 'edge_index': tensor([[ 0,  0,  0,  ..., 63, 63, 63],
        [ 3,  4,  5,  ..., 59, 61, 62]]), 'edge_attr': tensor([0.4777, 0.1937, 0.2155,  ..., 0.0821, 0.2952, 0.0661])}}
Data object __dict__ in prepare_graph_data with covariance features: {'_edge_attr_cls': <class 'torch_geometric.data.data.DataEdgeAttr'>, '_tensor_attr_cls': <class 'torch_geometric.data.data.DataTensorAttr'>, '_store': {'x': tensor([[ 0.0000, -0.0849,  0.0823,  ...,  0.4246,  0.0573,  0.1067],
        [-0.0849,  0.0000, -0.0005,  ..., -0.0036, -0.0615,  0.0530],
        [ 0.0823, -0.0005,  0.0000,  ...,  0.0600,  0.2248,  0.0465],
        ...,
        [ 0.4246, -0.0036,  0.0600,  ...,  0.0000,  0.0698,  0.0961],
        [ 0.0573, -0.0615,  0.2248,  ...,  0.0698,  0.0000,  0.0564],
        [ 0.1067,  0.0530,  0.0465,  ...,  0.0961,  0.0564,  0.0000]]), 'edge_index': tensor([[ 0,  0,  0,  ..., 63, 63, 63],
        [ 2,  3,  6,  ..., 60, 61, 62]]), 'edge_attr': tensor([0.1005, 0.5607, 0.1155,  ..., 0.1060, 0.2760, 0.1297])}}
Data object __dict__ in prepare_graph_data with covariance features: {'_edge_attr_cls': <class 'torch_geometric.data.data.DataEdgeAttr'>, '_tensor_attr_cls': <class 'torch_geometric.data.data.DataTensorAttr'>, '_store': {'x': tensor([[0.0000, 0.0777, 0.1825,  ..., 0.5104, 0.0178, 0.2275],
        [0.0777, 0.0000, 0.1301,  ..., 0.0664, 0.0234, 0.0378],
        [0.1825, 0.1301, 0.0000,  ..., 0.1498, 0.1782, 0.1140],
        ...,
        [0.5104, 0.0664, 0.1498,  ..., 0.0000, 0.0149, 0.1741],
        [0.0178, 0.0234, 0.1782,  ..., 0.0149, 0.0000, 0.0665],
        [0.2275, 0.0378, 0.1140,  ..., 0.1741, 0.0665, 0.0000]]), 'edge_index': tensor([[ 0,  0,  0,  ..., 63, 63, 63],
        [ 1,  2,  3,  ..., 60, 61, 62]]), 'edge_attr': tensor([0.0840, 0.3271, 0.6851,  ..., 0.0621, 0.3526, 0.0713])}}
Data object __dict__ in prepare_graph_data with covariance features: {'_edge_attr_cls': <class 'torch_geometric.data.data.DataEdgeAttr'>, '_tensor_attr_cls': <class 'torch_geometric.data.data.DataTensorAttr'>, '_store': {'x': tensor([[ 0.0000,  0.0760,  0.1287,  ...,  0.4014,  0.0388,  0.1671],
        [ 0.0760,  0.0000,  0.0550,  ...,  0.0199,  0.2116,  0.2046],
        [ 0.1287,  0.0550,  0.0000,  ...,  0.0996,  0.0423,  0.1041],
        ...,
        [ 0.4014,  0.0199,  0.0996,  ...,  0.0000, -0.0129,  0.1409],
        [ 0.0388,  0.2116,  0.0423,  ..., -0.0129,  0.0000,  0.1847],
        [ 0.1671,  0.2046,  0.1041,  ...,  0.1409,  0.1847,  0.0000]]), 'edge_index': tensor([[ 0,  0,  0,  ..., 63, 63, 63],
        [ 2,  3,  4,  ..., 60, 61, 62]]), 'edge_attr': tensor([0.0607, 0.3847, 0.3125,  ..., 0.3828, 0.1930, 0.3511])}}
Data object __dict__ in prepare_graph_data with covariance features: {'_edge_attr_cls': <class 'torch_geometric.data.data.DataEdgeAttr'>, '_tensor_attr_cls': <class 'torch_geometric.data.data.DataTensorAttr'>, '_store': {'x': tensor([[0.0000, 0.3339, 0.1132,  ..., 0.2176, 0.0448, 0.1063],
        [0.3339, 0.0000, 0.0235,  ..., 0.1650, 0.0552, 0.1103],
        [0.1132, 0.0235, 0.0000,  ..., 0.1271, 0.0891, 0.0144],
        ...,
        [0.2176, 0.1650, 0.1271,  ..., 0.0000, 0.0359, 0.0491],
        [0.0448, 0.0552, 0.0891,  ..., 0.0359, 0.0000, 0.0364],
        [0.1063, 0.1103, 0.0144,  ..., 0.0491, 0.0364, 0.0000]]), 'edge_index': tensor([[ 0,  0,  0,  ..., 63, 63, 63],
        [ 1,  2,  3,  ..., 60, 61, 62]]), 'edge_attr': tensor([0.5002, 0.1793, 0.5244,  ..., 0.1763, 0.1525, 0.1618])}}
Data object __dict__ in prepare_graph_data with covariance features: {'_edge_attr_cls': <class 'torch_geometric.data.data.DataEdgeAttr'>, '_tensor_attr_cls': <class 'torch_geometric.data.data.DataTensorAttr'>, '_store': {'x': tensor([[0.0000e+00, 2.7495e-03, 1.2980e-01,  ..., 3.3422e-01, 1.9571e-01,
         1.5283e-02],
        [2.7495e-03, 0.0000e+00, 4.9271e-03,  ..., 1.8664e-03, 3.2097e-03,
         1.4198e-04],
        [1.2980e-01, 4.9271e-03, 0.0000e+00,  ..., 8.4436e-02, 1.6599e-01,
         7.3429e-03],
        ...,
        [3.3422e-01, 1.8664e-03, 8.4436e-02,  ..., 0.0000e+00, 1.2525e-01,
         9.3729e-03],
        [1.9571e-01, 3.2097e-03, 1.6599e-01,  ..., 1.2525e-01, 0.0000e+00,
         1.5580e-02],
        [1.5283e-02, 1.4198e-04, 7.3429e-03,  ..., 9.3729e-03, 1.5580e-02,
         0.0000e+00]]), 'edge_index': tensor([[ 0,  0,  0,  ..., 63, 63, 63],
        [ 1,  2,  3,  ..., 60, 61, 62]]), 'edge_attr': tensor([0.0833, 0.5573, 0.7113,  ..., 0.4006, 0.4232, 0.2832])}}
Data object __dict__ in prepare_graph_data with covariance features: {'_edge_attr_cls': <class 'torch_geometric.data.data.DataEdgeAttr'>, '_tensor_attr_cls': <class 'torch_geometric.data.data.DataTensorAttr'>, '_store': {'x': tensor([[ 0.0000,  0.1333, -0.2016,  ...,  0.4937, -0.0984,  0.1610],
        [ 0.1333,  0.0000,  0.0794,  ...,  0.1995, -0.0630,  0.0994],
        [-0.2016,  0.0794,  0.0000,  ..., -0.1724,  0.0381, -0.0259],
        ...,
        [ 0.4937,  0.1995, -0.1724,  ...,  0.0000, -0.1081,  0.1406],
        [-0.0984, -0.0630,  0.0381,  ..., -0.1081,  0.0000, -0.0065],
        [ 0.1610,  0.0994, -0.0259,  ...,  0.1406, -0.0065,  0.0000]]), 'edge_index': tensor([[ 0,  0,  0,  ..., 63, 63, 63],
        [ 1,  3,  4,  ..., 59, 60, 61]]), 'edge_attr': tensor([0.1468, 0.5400, 0.0838,  ..., 0.0547, 0.1474, 0.3015])}}

--- Starting Hyperparameter Grid Search ---

--- Evaluating o_weight=0.5, co_weight=1.0 ---
 Initializing CAL_GAT model...

--- Fold 1/5 ---
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch_geometric\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
 Initializing optimizer and scheduler for Fold 1...
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch\optim\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
 Starting training and validation for Fold 1 with patience=10 epochs...
  Epoch 1/500 - Fold 1: Train Loss: 1.4668, Val Loss: 1.0407, Val Acc: 0.5000, Best Val Acc: 0.5000, No Improvement Epochs: 0
  Epoch 2/500 - Fold 1: Train Loss: 1.2623, Val Loss: 1.0410, Val Acc: 0.5000, Best Val Acc: 0.5000, No Improvement Epochs: 1
  Epoch 3/500 - Fold 1: Train Loss: 1.5865, Val Loss: 1.0405, Val Acc: 0.5000, Best Val Acc: 0.5000, No Improvement Epochs: 0
  Epoch 4/500 - Fold 1: Train Loss: 1.1527, Val Loss: 1.0403, Val Acc: 0.5000, Best Val Acc: 0.5000, No Improvement Epochs: 0
  Epoch 5/500 - Fold 1: Train Loss: 1.0903, Val Loss: 1.0402, Val Acc: 0.5000, Best Val Acc: 0.5000, No Improvement Epochs: 0
  Epoch 6/500 - Fold 1: Train Loss: 1.1131, Val Loss: 1.0405, Val Acc: 0.5000, Best Val Acc: 0.5000, No Improvement Epochs: 1
  Epoch 7/500 - Fold 1: Train Loss: 1.1644, Val Loss: 1.0411, Val Acc: 0.5000, Best Val Acc: 0.5000, No Improvement Epochs: 2
  Epoch 8/500 - Fold 1: Train Loss: 1.2571, Val Loss: 1.0414, Val Acc: 0.5000, Best Val Acc: 0.5000, No Improvement Epochs: 3
  Epoch 9/500 - Fold 1: Train Loss: 1.2357, Val Loss: 1.0415, Val Acc: 0.5000, Best Val Acc: 0.5000, No Improvement Epochs: 4
  Epoch 10/500 - Fold 1: Train Loss: 0.9733, Val Loss: 1.0421, Val Acc: 0.5000, Best Val Acc: 0.5000, No Improvement Epochs: 5
  Epoch 11/500 - Fold 1: Train Loss: 0.9911, Val Loss: 1.0425, Val Acc: 0.5000, Best Val Acc: 0.5000, No Improvement Epochs: 6
  Epoch 12/500 - Fold 1: Train Loss: 1.2530, Val Loss: 1.0426, Val Acc: 0.5000, Best Val Acc: 0.5000, No Improvement Epochs: 7
  Epoch 13/500 - Fold 1: Train Loss: 0.9632, Val Loss: 1.0427, Val Acc: 0.5000, Best Val Acc: 0.5000, No Improvement Epochs: 8
  Epoch 14/500 - Fold 1: Train Loss: 0.8942, Val Loss: 1.0427, Val Acc: 0.5000, Best Val Acc: 0.5000, No Improvement Epochs: 9
  Epoch 15/500 - Fold 1: Train Loss: 0.9347, Val Loss: 1.0425, Val Acc: 0.6667, Best Val Acc: 0.5000, No Improvement Epochs: 10
  Early stopping triggered: Validation loss did not improve for 10 epochs.
  Fold 1 Training finished (or stopped early). Loading best model from validation...
  Fold 1 Final Validation Loss: 1.0425, Final Validation Accuracy: 0.6667
  Fold 1 Confusion Matrix:
[[1 2]
 [0 3]]

--- Fold 2/5 ---
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch_geometric\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
 Initializing optimizer and scheduler for Fold 2...
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch\optim\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
 Starting training and validation for Fold 2 with patience=10 epochs...
  Epoch 1/500 - Fold 2: Train Loss: 1.3047, Val Loss: 0.9849, Val Acc: 0.6000, Best Val Acc: 0.6000, No Improvement Epochs: 0
  Epoch 2/500 - Fold 2: Train Loss: 0.9859, Val Loss: 0.9776, Val Acc: 0.6000, Best Val Acc: 0.6000, No Improvement Epochs: 0
  Epoch 3/500 - Fold 2: Train Loss: 1.0781, Val Loss: 0.9679, Val Acc: 0.6000, Best Val Acc: 0.6000, No Improvement Epochs: 0
  Epoch 4/500 - Fold 2: Train Loss: 0.9961, Val Loss: 0.9610, Val Acc: 0.6000, Best Val Acc: 0.6000, No Improvement Epochs: 0
  Epoch 5/500 - Fold 2: Train Loss: 0.9220, Val Loss: 0.9549, Val Acc: 0.6000, Best Val Acc: 0.6000, No Improvement Epochs: 0
  Epoch 6/500 - Fold 2: Train Loss: 0.8724, Val Loss: 0.9493, Val Acc: 0.6000, Best Val Acc: 0.6000, No Improvement Epochs: 0
  Epoch 7/500 - Fold 2: Train Loss: 1.0402, Val Loss: 0.9427, Val Acc: 0.6000, Best Val Acc: 0.6000, No Improvement Epochs: 0
  Epoch 8/500 - Fold 2: Train Loss: 1.0945, Val Loss: 0.9361, Val Acc: 0.6000, Best Val Acc: 0.6000, No Improvement Epochs: 0
  Epoch 9/500 - Fold 2: Train Loss: 1.1015, Val Loss: 0.9299, Val Acc: 0.6000, Best Val Acc: 0.6000, No Improvement Epochs: 0
  Epoch 10/500 - Fold 2: Train Loss: 0.8516, Val Loss: 0.9251, Val Acc: 0.4000, Best Val Acc: 0.4000, No Improvement Epochs: 0
  Epoch 11/500 - Fold 2: Train Loss: 0.6914, Val Loss: 0.9206, Val Acc: 0.6000, Best Val Acc: 0.6000, No Improvement Epochs: 0
  Epoch 12/500 - Fold 2: Train Loss: 0.8957, Val Loss: 0.9185, Val Acc: 0.6000, Best Val Acc: 0.6000, No Improvement Epochs: 0
  Epoch 13/500 - Fold 2: Train Loss: 0.7433, Val Loss: 0.9153, Val Acc: 0.6000, Best Val Acc: 0.6000, No Improvement Epochs: 0
  Epoch 14/500 - Fold 2: Train Loss: 0.9228, Val Loss: 0.9156, Val Acc: 0.6000, Best Val Acc: 0.6000, No Improvement Epochs: 1
  Epoch 15/500 - Fold 2: Train Loss: 0.9409, Val Loss: 0.9169, Val Acc: 0.6000, Best Val Acc: 0.6000, No Improvement Epochs: 2
  Epoch 16/500 - Fold 2: Train Loss: 0.7206, Val Loss: 0.9193, Val Acc: 0.6000, Best Val Acc: 0.6000, No Improvement Epochs: 3
  Epoch 17/500 - Fold 2: Train Loss: 1.0524, Val Loss: 0.9219, Val Acc: 0.6000, Best Val Acc: 0.6000, No Improvement Epochs: 4
  Epoch 18/500 - Fold 2: Train Loss: 0.9672, Val Loss: 0.9287, Val Acc: 0.6000, Best Val Acc: 0.6000, No Improvement Epochs: 5
  Epoch 19/500 - Fold 2: Train Loss: 0.6008, Val Loss: 0.9353, Val Acc: 0.6000, Best Val Acc: 0.6000, No Improvement Epochs: 6
  Epoch 20/500 - Fold 2: Train Loss: 0.7886, Val Loss: 0.9392, Val Acc: 0.6000, Best Val Acc: 0.6000, No Improvement Epochs: 7
  Epoch 21/500 - Fold 2: Train Loss: 0.7268, Val Loss: 0.9458, Val Acc: 0.6000, Best Val Acc: 0.6000, No Improvement Epochs: 8
  Epoch 22/500 - Fold 2: Train Loss: 0.8192, Val Loss: 0.9560, Val Acc: 0.6000, Best Val Acc: 0.6000, No Improvement Epochs: 9
  Epoch 23/500 - Fold 2: Train Loss: 0.8132, Val Loss: 0.9647, Val Acc: 0.6000, Best Val Acc: 0.6000, No Improvement Epochs: 10
  Early stopping triggered: Validation loss did not improve for 10 epochs.
  Fold 2 Training finished (or stopped early). Loading best model from validation...
  Fold 2 Final Validation Loss: 0.9647, Final Validation Accuracy: 0.6000
  Fold 2 Confusion Matrix:
[[1 1]
 [1 2]]

--- Fold 3/5 ---
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch_geometric\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
 Initializing optimizer and scheduler for Fold 3...
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch\optim\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
 Starting training and validation for Fold 3 with patience=10 epochs...
  Epoch 1/500 - Fold 3: Train Loss: 0.8650, Val Loss: 0.9130, Val Acc: 0.6000, Best Val Acc: 0.6000, No Improvement Epochs: 0
  Epoch 2/500 - Fold 3: Train Loss: 0.7629, Val Loss: 0.9157, Val Acc: 0.6000, Best Val Acc: 0.6000, No Improvement Epochs: 1
  Epoch 3/500 - Fold 3: Train Loss: 0.8879, Val Loss: 0.9157, Val Acc: 0.6000, Best Val Acc: 0.6000, No Improvement Epochs: 2
  Epoch 4/500 - Fold 3: Train Loss: 0.8470, Val Loss: 0.9146, Val Acc: 0.6000, Best Val Acc: 0.6000, No Improvement Epochs: 3
  Epoch 5/500 - Fold 3: Train Loss: 0.8262, Val Loss: 0.9060, Val Acc: 0.6000, Best Val Acc: 0.6000, No Improvement Epochs: 0
  Epoch 6/500 - Fold 3: Train Loss: 0.7452, Val Loss: 0.8999, Val Acc: 0.6000, Best Val Acc: 0.6000, No Improvement Epochs: 0
  Epoch 7/500 - Fold 3: Train Loss: 0.7932, Val Loss: 0.8960, Val Acc: 0.6000, Best Val Acc: 0.6000, No Improvement Epochs: 0
  Epoch 8/500 - Fold 3: Train Loss: 0.6119, Val Loss: 0.8956, Val Acc: 0.6000, Best Val Acc: 0.6000, No Improvement Epochs: 0
  Epoch 9/500 - Fold 3: Train Loss: 0.8230, Val Loss: 0.8922, Val Acc: 0.6000, Best Val Acc: 0.6000, No Improvement Epochs: 0
  Epoch 10/500 - Fold 3: Train Loss: 0.7686, Val Loss: 0.8850, Val Acc: 0.6000, Best Val Acc: 0.6000, No Improvement Epochs: 0
  Epoch 11/500 - Fold 3: Train Loss: 0.5889, Val Loss: 0.8824, Val Acc: 0.6000, Best Val Acc: 0.6000, No Improvement Epochs: 0
  Epoch 12/500 - Fold 3: Train Loss: 0.6416, Val Loss: 0.8771, Val Acc: 0.6000, Best Val Acc: 0.6000, No Improvement Epochs: 0
  Epoch 13/500 - Fold 3: Train Loss: 0.7033, Val Loss: 0.8725, Val Acc: 0.6000, Best Val Acc: 0.6000, No Improvement Epochs: 0
  Epoch 14/500 - Fold 3: Train Loss: 0.7621, Val Loss: 0.8685, Val Acc: 0.6000, Best Val Acc: 0.6000, No Improvement Epochs: 0
  Epoch 15/500 - Fold 3: Train Loss: 0.7949, Val Loss: 0.8616, Val Acc: 0.6000, Best Val Acc: 0.6000, No Improvement Epochs: 0
  Epoch 16/500 - Fold 3: Train Loss: 0.7089, Val Loss: 0.8539, Val Acc: 0.6000, Best Val Acc: 0.6000, No Improvement Epochs: 0
  Epoch 17/500 - Fold 3: Train Loss: 0.5073, Val Loss: 0.8456, Val Acc: 0.6000, Best Val Acc: 0.6000, No Improvement Epochs: 0
  Epoch 18/500 - Fold 3: Train Loss: 0.5296, Val Loss: 0.8384, Val Acc: 0.6000, Best Val Acc: 0.6000, No Improvement Epochs: 0
  Epoch 19/500 - Fold 3: Train Loss: 0.5369, Val Loss: 0.8320, Val Acc: 0.8000, Best Val Acc: 0.8000, No Improvement Epochs: 0
  Epoch 20/500 - Fold 3: Train Loss: 0.5786, Val Loss: 0.8242, Val Acc: 0.8000, Best Val Acc: 0.8000, No Improvement Epochs: 0
  Epoch 21/500 - Fold 3: Train Loss: 0.6282, Val Loss: 0.8158, Val Acc: 0.8000, Best Val Acc: 0.8000, No Improvement Epochs: 0
  Epoch 22/500 - Fold 3: Train Loss: 0.6771, Val Loss: 0.8072, Val Acc: 0.8000, Best Val Acc: 0.8000, No Improvement Epochs: 0
  Epoch 23/500 - Fold 3: Train Loss: 0.4804, Val Loss: 0.8005, Val Acc: 0.8000, Best Val Acc: 0.8000, No Improvement Epochs: 0
  Epoch 24/500 - Fold 3: Train Loss: 0.5417, Val Loss: 0.7927, Val Acc: 0.8000, Best Val Acc: 0.8000, No Improvement Epochs: 0
  Epoch 25/500 - Fold 3: Train Loss: 0.5949, Val Loss: 0.7865, Val Acc: 0.8000, Best Val Acc: 0.8000, No Improvement Epochs: 0
  Epoch 26/500 - Fold 3: Train Loss: 0.5267, Val Loss: 0.7820, Val Acc: 0.8000, Best Val Acc: 0.8000, No Improvement Epochs: 0
  Epoch 27/500 - Fold 3: Train Loss: 0.4586, Val Loss: 0.7727, Val Acc: 0.8000, Best Val Acc: 0.8000, No Improvement Epochs: 0
  Epoch 28/500 - Fold 3: Train Loss: 0.4334, Val Loss: 0.7642, Val Acc: 0.8000, Best Val Acc: 0.8000, No Improvement Epochs: 0
  Epoch 29/500 - Fold 3: Train Loss: 0.6755, Val Loss: 0.7552, Val Acc: 0.8000, Best Val Acc: 0.8000, No Improvement Epochs: 0
  Epoch 30/500 - Fold 3: Train Loss: 0.5268, Val Loss: 0.7486, Val Acc: 0.8000, Best Val Acc: 0.8000, No Improvement Epochs: 0
  Epoch 31/500 - Fold 3: Train Loss: 0.5011, Val Loss: 0.7420, Val Acc: 0.8000, Best Val Acc: 0.8000, No Improvement Epochs: 0
  Epoch 32/500 - Fold 3: Train Loss: 0.4997, Val Loss: 0.7325, Val Acc: 0.8000, Best Val Acc: 0.8000, No Improvement Epochs: 0
  Epoch 33/500 - Fold 3: Train Loss: 0.5294, Val Loss: 0.7264, Val Acc: 0.8000, Best Val Acc: 0.8000, No Improvement Epochs: 0
  Epoch 34/500 - Fold 3: Train Loss: 0.5113, Val Loss: 0.7187, Val Acc: 0.8000, Best Val Acc: 0.8000, No Improvement Epochs: 0
  Epoch 35/500 - Fold 3: Train Loss: 0.4898, Val Loss: 0.7123, Val Acc: 0.8000, Best Val Acc: 0.8000, No Improvement Epochs: 0
  Epoch 36/500 - Fold 3: Train Loss: 0.4980, Val Loss: 0.7051, Val Acc: 0.8000, Best Val Acc: 0.8000, No Improvement Epochs: 0
  Epoch 37/500 - Fold 3: Train Loss: 0.5836, Val Loss: 0.7008, Val Acc: 0.8000, Best Val Acc: 0.8000, No Improvement Epochs: 0
  Epoch 38/500 - Fold 3: Train Loss: 0.4743, Val Loss: 0.6960, Val Acc: 0.8000, Best Val Acc: 0.8000, No Improvement Epochs: 0
  Epoch 39/500 - Fold 3: Train Loss: 0.5000, Val Loss: 0.6903, Val Acc: 0.8000, Best Val Acc: 0.8000, No Improvement Epochs: 0
  Epoch 40/500 - Fold 3: Train Loss: 0.4849, Val Loss: 0.6856, Val Acc: 0.8000, Best Val Acc: 0.8000, No Improvement Epochs: 0
  Epoch 41/500 - Fold 3: Train Loss: 0.5847, Val Loss: 0.6820, Val Acc: 0.8000, Best Val Acc: 0.8000, No Improvement Epochs: 0
  Epoch 42/500 - Fold 3: Train Loss: 0.4784, Val Loss: 0.6799, Val Acc: 0.8000, Best Val Acc: 0.8000, No Improvement Epochs: 0
  Epoch 43/500 - Fold 3: Train Loss: 0.3837, Val Loss: 0.6794, Val Acc: 0.8000, Best Val Acc: 0.8000, No Improvement Epochs: 0
  Epoch 44/500 - Fold 3: Train Loss: 0.5493, Val Loss: 0.6777, Val Acc: 0.8000, Best Val Acc: 0.8000, No Improvement Epochs: 0
  Epoch 45/500 - Fold 3: Train Loss: 0.4369, Val Loss: 0.6776, Val Acc: 0.8000, Best Val Acc: 0.8000, No Improvement Epochs: 0
  Epoch 46/500 - Fold 3: Train Loss: 0.4530, Val Loss: 0.6805, Val Acc: 0.8000, Best Val Acc: 0.8000, No Improvement Epochs: 1
  Epoch 47/500 - Fold 3: Train Loss: 0.4985, Val Loss: 0.6811, Val Acc: 0.8000, Best Val Acc: 0.8000, No Improvement Epochs: 2
  Epoch 48/500 - Fold 3: Train Loss: 0.4215, Val Loss: 0.6826, Val Acc: 0.8000, Best Val Acc: 0.8000, No Improvement Epochs: 3
  Epoch 49/500 - Fold 3: Train Loss: 0.4374, Val Loss: 0.6823, Val Acc: 0.8000, Best Val Acc: 0.8000, No Improvement Epochs: 4
  Epoch 50/500 - Fold 3: Train Loss: 0.4348, Val Loss: 0.6818, Val Acc: 0.8000, Best Val Acc: 0.8000, No Improvement Epochs: 5
  Epoch 51/500 - Fold 3: Train Loss: 0.4399, Val Loss: 0.6811, Val Acc: 0.8000, Best Val Acc: 0.8000, No Improvement Epochs: 6
  Epoch 52/500 - Fold 3: Train Loss: 0.3627, Val Loss: 0.6806, Val Acc: 0.8000, Best Val Acc: 0.8000, No Improvement Epochs: 7
  Epoch 53/500 - Fold 3: Train Loss: 0.4823, Val Loss: 0.6820, Val Acc: 0.8000, Best Val Acc: 0.8000, No Improvement Epochs: 8
  Epoch 54/500 - Fold 3: Train Loss: 0.3559, Val Loss: 0.6818, Val Acc: 0.8000, Best Val Acc: 0.8000, No Improvement Epochs: 9
  Epoch 55/500 - Fold 3: Train Loss: 0.4062, Val Loss: 0.6823, Val Acc: 0.8000, Best Val Acc: 0.8000, No Improvement Epochs: 10
  Early stopping triggered: Validation loss did not improve for 10 epochs.
  Fold 3 Training finished (or stopped early). Loading best model from validation...
  Fold 3 Final Validation Loss: 0.6823, Final Validation Accuracy: 0.8000
  Fold 3 Confusion Matrix:
[[2 1]
 [0 2]]

--- Fold 4/5 ---
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch_geometric\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
 Initializing optimizer and scheduler for Fold 4...
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch\optim\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
 Starting training and validation for Fold 4 with patience=10 epochs...
  Epoch 1/500 - Fold 4: Train Loss: 0.4685, Val Loss: 0.1610, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 2/500 - Fold 4: Train Loss: 0.4510, Val Loss: 0.1519, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 3/500 - Fold 4: Train Loss: 0.4721, Val Loss: 0.1422, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 4/500 - Fold 4: Train Loss: 0.4877, Val Loss: 0.1363, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 5/500 - Fold 4: Train Loss: 0.4979, Val Loss: 0.1314, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 6/500 - Fold 4: Train Loss: 0.4022, Val Loss: 0.1256, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 7/500 - Fold 4: Train Loss: 0.5747, Val Loss: 0.1210, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 8/500 - Fold 4: Train Loss: 0.4715, Val Loss: 0.1180, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 9/500 - Fold 4: Train Loss: 0.4227, Val Loss: 0.1170, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 10/500 - Fold 4: Train Loss: 0.4792, Val Loss: 0.1191, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 11/500 - Fold 4: Train Loss: 0.4115, Val Loss: 0.1228, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 2
  Epoch 12/500 - Fold 4: Train Loss: 0.4787, Val Loss: 0.1258, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 3
  Epoch 13/500 - Fold 4: Train Loss: 0.4663, Val Loss: 0.1288, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 4
  Epoch 14/500 - Fold 4: Train Loss: 0.2991, Val Loss: 0.1314, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 5
  Epoch 15/500 - Fold 4: Train Loss: 0.3781, Val Loss: 0.1332, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 6
  Epoch 16/500 - Fold 4: Train Loss: 0.4416, Val Loss: 0.1346, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 7
  Epoch 17/500 - Fold 4: Train Loss: 0.3268, Val Loss: 0.1344, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 8
  Epoch 18/500 - Fold 4: Train Loss: 0.4599, Val Loss: 0.1350, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 9
  Epoch 19/500 - Fold 4: Train Loss: 0.3674, Val Loss: 0.1369, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 10
  Early stopping triggered: Validation loss did not improve for 10 epochs.
  Fold 4 Training finished (or stopped early). Loading best model from validation...
  Fold 4 Final Validation Loss: 0.1369, Final Validation Accuracy: 1.0000
  Fold 4 Confusion Matrix:
[[3 0]
 [0 2]]

--- Fold 5/5 ---
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch_geometric\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
 Initializing optimizer and scheduler for Fold 5...
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch\optim\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
 Starting training and validation for Fold 5 with patience=10 epochs...
  Epoch 1/500 - Fold 5: Train Loss: 0.4041, Val Loss: 0.1963, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 2/500 - Fold 5: Train Loss: 0.3938, Val Loss: 0.1968, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 3/500 - Fold 5: Train Loss: 0.3005, Val Loss: 0.1986, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 2
  Epoch 4/500 - Fold 5: Train Loss: 0.3547, Val Loss: 0.2018, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 3
  Epoch 5/500 - Fold 5: Train Loss: 0.4217, Val Loss: 0.2031, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 4
  Epoch 6/500 - Fold 5: Train Loss: 0.3282, Val Loss: 0.2060, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 5
  Epoch 7/500 - Fold 5: Train Loss: 0.3494, Val Loss: 0.2067, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 6
  Epoch 8/500 - Fold 5: Train Loss: 0.2629, Val Loss: 0.2105, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 7
  Epoch 9/500 - Fold 5: Train Loss: 0.3430, Val Loss: 0.2117, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 8
  Epoch 10/500 - Fold 5: Train Loss: 0.2984, Val Loss: 0.2152, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 9
  Epoch 11/500 - Fold 5: Train Loss: 0.3226, Val Loss: 0.2184, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 10
  Early stopping triggered: Validation loss did not improve for 10 epochs.
  Fold 5 Training finished (or stopped early). Loading best model from validation...
  Fold 5 Final Validation Loss: 0.2184, Final Validation Accuracy: 1.0000
  Fold 5 Confusion Matrix:
[[3 0]
 [0 2]]

--- Hyperparameter Combination: o_weight=0.5, co_weight=1.0 ---
Average Validation Accuracy: 0.8133 Â± 0.1655
Average Validation Loss: 0.6089

--- Fold 1/5 ---
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch_geometric\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
 Initializing optimizer and scheduler for Fold 1...
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch\optim\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
 Starting training and validation for Fold 1 with patience=10 epochs...
  Epoch 1/500 - Fold 1: Train Loss: 0.3342, Val Loss: 0.2116, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 2/500 - Fold 1: Train Loss: 0.2131, Val Loss: 0.2163, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 3/500 - Fold 1: Train Loss: 0.3308, Val Loss: 0.2169, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 2
  Epoch 4/500 - Fold 1: Train Loss: 0.3233, Val Loss: 0.2195, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 3
  Epoch 5/500 - Fold 1: Train Loss: 0.3050, Val Loss: 0.2226, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 4
  Epoch 6/500 - Fold 1: Train Loss: 0.3316, Val Loss: 0.2257, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 5
  Epoch 7/500 - Fold 1: Train Loss: 0.2708, Val Loss: 0.2286, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 6
  Epoch 8/500 - Fold 1: Train Loss: 0.3292, Val Loss: 0.2303, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 7
  Epoch 9/500 - Fold 1: Train Loss: 0.3230, Val Loss: 0.2320, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 8
  Epoch 10/500 - Fold 1: Train Loss: 0.2808, Val Loss: 0.2360, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 9
  Epoch 11/500 - Fold 1: Train Loss: 0.2273, Val Loss: 0.2395, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 10
  Early stopping triggered: Validation loss did not improve for 10 epochs.
  Fold 1 Training finished (or stopped early). Loading best model from validation...
  Fold 1 Final Validation Loss: 0.2395, Final Validation Accuracy: 1.0000
  Fold 1 Confusion Matrix:
[[3 0]
 [0 3]]

--- Fold 2/5 ---
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch_geometric\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
 Initializing optimizer and scheduler for Fold 2...
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch\optim\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
 Starting training and validation for Fold 2 with patience=10 epochs...
  Epoch 1/500 - Fold 2: Train Loss: 0.3028, Val Loss: 0.1941, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 2/500 - Fold 2: Train Loss: 0.3735, Val Loss: 0.1982, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 3/500 - Fold 2: Train Loss: 0.3639, Val Loss: 0.1945, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 2
  Epoch 4/500 - Fold 2: Train Loss: 0.2818, Val Loss: 0.1940, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 5/500 - Fold 2: Train Loss: 0.3169, Val Loss: 0.1907, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 6/500 - Fold 2: Train Loss: 0.3302, Val Loss: 0.1871, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 7/500 - Fold 2: Train Loss: 0.2844, Val Loss: 0.1852, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 8/500 - Fold 2: Train Loss: 0.3253, Val Loss: 0.1827, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 9/500 - Fold 2: Train Loss: 0.2445, Val Loss: 0.1815, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 10/500 - Fold 2: Train Loss: 0.2367, Val Loss: 0.1770, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 11/500 - Fold 2: Train Loss: 0.2894, Val Loss: 0.1797, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 12/500 - Fold 2: Train Loss: 0.4156, Val Loss: 0.1829, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 2
  Epoch 13/500 - Fold 2: Train Loss: 0.2523, Val Loss: 0.1851, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 3
  Epoch 14/500 - Fold 2: Train Loss: 0.3487, Val Loss: 0.1909, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 4
  Epoch 15/500 - Fold 2: Train Loss: 0.2698, Val Loss: 0.2012, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 5
  Epoch 16/500 - Fold 2: Train Loss: 0.2864, Val Loss: 0.2131, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 6
  Epoch 17/500 - Fold 2: Train Loss: 0.2743, Val Loss: 0.2229, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 7
  Epoch 18/500 - Fold 2: Train Loss: 0.2960, Val Loss: 0.2279, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 8
  Epoch 19/500 - Fold 2: Train Loss: 0.2531, Val Loss: 0.2314, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 9
  Epoch 20/500 - Fold 2: Train Loss: 0.2842, Val Loss: 0.2270, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 10
  Early stopping triggered: Validation loss did not improve for 10 epochs.
  Fold 2 Training finished (or stopped early). Loading best model from validation...
  Fold 2 Final Validation Loss: 0.2270, Final Validation Accuracy: 1.0000
  Fold 2 Confusion Matrix:
[[2 0]
 [0 3]]

--- Fold 3/5 ---
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch_geometric\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
 Initializing optimizer and scheduler for Fold 3...
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch\optim\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
 Starting training and validation for Fold 3 with patience=10 epochs...
  Epoch 1/500 - Fold 3: Train Loss: 0.2414, Val Loss: 0.1386, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 2/500 - Fold 3: Train Loss: 0.2739, Val Loss: 0.1518, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 3/500 - Fold 3: Train Loss: 0.2179, Val Loss: 0.1602, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 2
  Epoch 4/500 - Fold 3: Train Loss: 0.2009, Val Loss: 0.1641, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 3
  Epoch 5/500 - Fold 3: Train Loss: 0.2651, Val Loss: 0.1678, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 4
  Epoch 6/500 - Fold 3: Train Loss: 0.2049, Val Loss: 0.1720, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 5
  Epoch 7/500 - Fold 3: Train Loss: 0.2475, Val Loss: 0.1750, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 6
  Epoch 8/500 - Fold 3: Train Loss: 0.2102, Val Loss: 0.1751, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 7
  Epoch 9/500 - Fold 3: Train Loss: 0.2195, Val Loss: 0.1734, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 8
  Epoch 10/500 - Fold 3: Train Loss: 0.2086, Val Loss: 0.1725, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 9
  Epoch 11/500 - Fold 3: Train Loss: 0.3809, Val Loss: 0.1717, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 10
  Early stopping triggered: Validation loss did not improve for 10 epochs.
  Fold 3 Training finished (or stopped early). Loading best model from validation...
  Fold 3 Final Validation Loss: 0.1717, Final Validation Accuracy: 1.0000
  Fold 3 Confusion Matrix:
[[3 0]
 [0 2]]

--- Fold 4/5 ---
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch_geometric\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
 Initializing optimizer and scheduler for Fold 4...
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch\optim\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
 Starting training and validation for Fold 4 with patience=10 epochs...
  Epoch 1/500 - Fold 4: Train Loss: 0.2184, Val Loss: 0.1060, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 2/500 - Fold 4: Train Loss: 0.2316, Val Loss: 0.0979, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 3/500 - Fold 4: Train Loss: 0.2409, Val Loss: 0.0945, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 4/500 - Fold 4: Train Loss: 0.2676, Val Loss: 0.0891, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 5/500 - Fold 4: Train Loss: 0.1866, Val Loss: 0.0849, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 6/500 - Fold 4: Train Loss: 0.3091, Val Loss: 0.0820, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 7/500 - Fold 4: Train Loss: 0.3141, Val Loss: 0.0787, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 8/500 - Fold 4: Train Loss: 0.2289, Val Loss: 0.0763, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 9/500 - Fold 4: Train Loss: 0.2550, Val Loss: 0.0742, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 10/500 - Fold 4: Train Loss: 0.2441, Val Loss: 0.0733, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 11/500 - Fold 4: Train Loss: 0.2490, Val Loss: 0.0731, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 12/500 - Fold 4: Train Loss: 0.2523, Val Loss: 0.0747, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 13/500 - Fold 4: Train Loss: 0.1989, Val Loss: 0.0758, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 2
  Epoch 14/500 - Fold 4: Train Loss: 0.2242, Val Loss: 0.0775, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 3
  Epoch 15/500 - Fold 4: Train Loss: 0.1877, Val Loss: 0.0794, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 4
  Epoch 16/500 - Fold 4: Train Loss: 0.1691, Val Loss: 0.0816, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 5
  Epoch 17/500 - Fold 4: Train Loss: 0.1910, Val Loss: 0.0805, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 6
  Epoch 18/500 - Fold 4: Train Loss: 0.2587, Val Loss: 0.0798, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 7
  Epoch 19/500 - Fold 4: Train Loss: 0.1917, Val Loss: 0.0792, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 8
  Epoch 20/500 - Fold 4: Train Loss: 0.2143, Val Loss: 0.0761, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 9
  Epoch 21/500 - Fold 4: Train Loss: 0.2386, Val Loss: 0.0740, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 10
  Early stopping triggered: Validation loss did not improve for 10 epochs.
  Fold 4 Training finished (or stopped early). Loading best model from validation...
  Fold 4 Final Validation Loss: 0.0740, Final Validation Accuracy: 1.0000
  Fold 4 Confusion Matrix:
[[3 0]
 [0 2]]

--- Fold 5/5 ---
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch_geometric\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
 Initializing optimizer and scheduler for Fold 5...
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch\optim\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
 Starting training and validation for Fold 5 with patience=10 epochs...
  Epoch 1/500 - Fold 5: Train Loss: 0.2794, Val Loss: 0.0779, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 2/500 - Fold 5: Train Loss: 0.3015, Val Loss: 0.0748, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 3/500 - Fold 5: Train Loss: 0.2193, Val Loss: 0.0727, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 4/500 - Fold 5: Train Loss: 0.2326, Val Loss: 0.0707, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 5/500 - Fold 5: Train Loss: 0.2367, Val Loss: 0.0696, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 6/500 - Fold 5: Train Loss: 0.3196, Val Loss: 0.0679, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 7/500 - Fold 5: Train Loss: 0.2054, Val Loss: 0.0664, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 8/500 - Fold 5: Train Loss: 0.3049, Val Loss: 0.0660, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 9/500 - Fold 5: Train Loss: 0.1842, Val Loss: 0.0657, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 10/500 - Fold 5: Train Loss: 0.2235, Val Loss: 0.0665, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 11/500 - Fold 5: Train Loss: 0.1967, Val Loss: 0.0662, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 2
  Epoch 12/500 - Fold 5: Train Loss: 0.2965, Val Loss: 0.0659, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 3
  Epoch 13/500 - Fold 5: Train Loss: 0.1494, Val Loss: 0.0651, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 14/500 - Fold 5: Train Loss: 0.2129, Val Loss: 0.0647, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 15/500 - Fold 5: Train Loss: 0.1763, Val Loss: 0.0642, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 16/500 - Fold 5: Train Loss: 0.2784, Val Loss: 0.0642, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 17/500 - Fold 5: Train Loss: 0.2236, Val Loss: 0.0648, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 18/500 - Fold 5: Train Loss: 0.1987, Val Loss: 0.0652, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 2
  Epoch 19/500 - Fold 5: Train Loss: 0.1905, Val Loss: 0.0656, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 3
  Epoch 20/500 - Fold 5: Train Loss: 0.2025, Val Loss: 0.0660, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 4
  Epoch 21/500 - Fold 5: Train Loss: 0.2124, Val Loss: 0.0658, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 5
  Epoch 22/500 - Fold 5: Train Loss: 0.2252, Val Loss: 0.0643, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 6
  Epoch 23/500 - Fold 5: Train Loss: 0.1929, Val Loss: 0.0635, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 24/500 - Fold 5: Train Loss: 0.2070, Val Loss: 0.0625, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 25/500 - Fold 5: Train Loss: 0.1602, Val Loss: 0.0630, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 26/500 - Fold 5: Train Loss: 0.2132, Val Loss: 0.0635, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 2
  Epoch 27/500 - Fold 5: Train Loss: 0.1688, Val Loss: 0.0630, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 3
  Epoch 28/500 - Fold 5: Train Loss: 0.2230, Val Loss: 0.0622, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 29/500 - Fold 5: Train Loss: 0.1944, Val Loss: 0.0621, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 30/500 - Fold 5: Train Loss: 0.2145, Val Loss: 0.0613, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 31/500 - Fold 5: Train Loss: 0.1242, Val Loss: 0.0604, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 32/500 - Fold 5: Train Loss: 0.2275, Val Loss: 0.0599, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 33/500 - Fold 5: Train Loss: 0.1380, Val Loss: 0.0598, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 34/500 - Fold 5: Train Loss: 0.0760, Val Loss: 0.0595, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 35/500 - Fold 5: Train Loss: 0.2375, Val Loss: 0.0592, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 36/500 - Fold 5: Train Loss: 0.1494, Val Loss: 0.0591, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 37/500 - Fold 5: Train Loss: 0.1459, Val Loss: 0.0593, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 38/500 - Fold 5: Train Loss: 0.2115, Val Loss: 0.0597, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 2
  Epoch 39/500 - Fold 5: Train Loss: 0.2004, Val Loss: 0.0597, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 3
  Epoch 40/500 - Fold 5: Train Loss: 0.2184, Val Loss: 0.0586, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 41/500 - Fold 5: Train Loss: 0.1499, Val Loss: 0.0575, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 42/500 - Fold 5: Train Loss: 0.1374, Val Loss: 0.0568, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 43/500 - Fold 5: Train Loss: 0.2767, Val Loss: 0.0561, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 44/500 - Fold 5: Train Loss: 0.1633, Val Loss: 0.0553, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 45/500 - Fold 5: Train Loss: 0.1214, Val Loss: 0.0550, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 46/500 - Fold 5: Train Loss: 0.1365, Val Loss: 0.0552, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 47/500 - Fold 5: Train Loss: 0.1561, Val Loss: 0.0551, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 2
  Epoch 48/500 - Fold 5: Train Loss: 0.2307, Val Loss: 0.0554, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 3
  Epoch 49/500 - Fold 5: Train Loss: 0.1314, Val Loss: 0.0553, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 4
  Epoch 50/500 - Fold 5: Train Loss: 0.1568, Val Loss: 0.0551, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 5
  Epoch 51/500 - Fold 5: Train Loss: 0.1555, Val Loss: 0.0545, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 52/500 - Fold 5: Train Loss: 0.1867, Val Loss: 0.0543, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 53/500 - Fold 5: Train Loss: 0.1475, Val Loss: 0.0536, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 54/500 - Fold 5: Train Loss: 0.1697, Val Loss: 0.0531, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 55/500 - Fold 5: Train Loss: 0.1964, Val Loss: 0.0517, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 56/500 - Fold 5: Train Loss: 0.1679, Val Loss: 0.0503, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 57/500 - Fold 5: Train Loss: 0.1094, Val Loss: 0.0493, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 58/500 - Fold 5: Train Loss: 0.1811, Val Loss: 0.0491, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 59/500 - Fold 5: Train Loss: 0.1264, Val Loss: 0.0487, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 60/500 - Fold 5: Train Loss: 0.1191, Val Loss: 0.0479, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 61/500 - Fold 5: Train Loss: 0.1505, Val Loss: 0.0474, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 62/500 - Fold 5: Train Loss: 0.1020, Val Loss: 0.0474, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 63/500 - Fold 5: Train Loss: 0.1954, Val Loss: 0.0474, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 64/500 - Fold 5: Train Loss: 0.1460, Val Loss: 0.0478, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 65/500 - Fold 5: Train Loss: 0.1364, Val Loss: 0.0477, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 2
  Epoch 66/500 - Fold 5: Train Loss: 0.1869, Val Loss: 0.0475, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 3
  Epoch 67/500 - Fold 5: Train Loss: 0.2182, Val Loss: 0.0481, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 4
  Epoch 68/500 - Fold 5: Train Loss: 0.1304, Val Loss: 0.0482, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 5
  Epoch 69/500 - Fold 5: Train Loss: 0.1661, Val Loss: 0.0481, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 6
  Epoch 70/500 - Fold 5: Train Loss: 0.0934, Val Loss: 0.0481, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 7
  Epoch 71/500 - Fold 5: Train Loss: 0.1574, Val Loss: 0.0480, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 8
  Epoch 72/500 - Fold 5: Train Loss: 0.1895, Val Loss: 0.0482, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 9
  Epoch 73/500 - Fold 5: Train Loss: 0.1311, Val Loss: 0.0484, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 10
  Early stopping triggered: Validation loss did not improve for 10 epochs.
  Fold 5 Training finished (or stopped early). Loading best model from validation...
  Fold 5 Final Validation Loss: 0.0484, Final Validation Accuracy: 1.0000
  Fold 5 Confusion Matrix:
[[3 0]
 [0 2]]

--- Hyperparameter Combination: o_weight=0.5, co_weight=1.0 ---
Average Validation Accuracy: 0.9067 Â± 0.1497
Average Validation Loss: 0.3805

--- Fold 1/5 ---
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch_geometric\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
 Initializing optimizer and scheduler for Fold 1...
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch\optim\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
 Starting training and validation for Fold 1 with patience=10 epochs...
  Epoch 1/500 - Fold 1: Train Loss: 0.1837, Val Loss: 0.0613, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 2/500 - Fold 1: Train Loss: 0.1250, Val Loss: 0.0623, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 3/500 - Fold 1: Train Loss: 0.1377, Val Loss: 0.0623, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 2
  Epoch 4/500 - Fold 1: Train Loss: 0.1295, Val Loss: 0.0618, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 3
  Epoch 5/500 - Fold 1: Train Loss: 0.1409, Val Loss: 0.0611, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 6/500 - Fold 1: Train Loss: 0.0871, Val Loss: 0.0601, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 7/500 - Fold 1: Train Loss: 0.1199, Val Loss: 0.0593, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 8/500 - Fold 1: Train Loss: 0.1934, Val Loss: 0.0591, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 9/500 - Fold 1: Train Loss: 0.1268, Val Loss: 0.0591, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 10/500 - Fold 1: Train Loss: 0.1799, Val Loss: 0.0591, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 11/500 - Fold 1: Train Loss: 0.1247, Val Loss: 0.0589, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 12/500 - Fold 1: Train Loss: 0.1407, Val Loss: 0.0582, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 13/500 - Fold 1: Train Loss: 0.1544, Val Loss: 0.0578, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 14/500 - Fold 1: Train Loss: 0.1736, Val Loss: 0.0575, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 15/500 - Fold 1: Train Loss: 0.1271, Val Loss: 0.0572, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 16/500 - Fold 1: Train Loss: 0.1352, Val Loss: 0.0573, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 17/500 - Fold 1: Train Loss: 0.1047, Val Loss: 0.0575, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 2
  Epoch 18/500 - Fold 1: Train Loss: 0.1349, Val Loss: 0.0577, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 3
  Epoch 19/500 - Fold 1: Train Loss: 0.1097, Val Loss: 0.0577, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 4
  Epoch 20/500 - Fold 1: Train Loss: 0.1663, Val Loss: 0.0575, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 5
  Epoch 21/500 - Fold 1: Train Loss: 0.1503, Val Loss: 0.0568, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 22/500 - Fold 1: Train Loss: 0.0849, Val Loss: 0.0562, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 23/500 - Fold 1: Train Loss: 0.1618, Val Loss: 0.0563, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 24/500 - Fold 1: Train Loss: 0.1144, Val Loss: 0.0562, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 2
  Epoch 25/500 - Fold 1: Train Loss: 0.2117, Val Loss: 0.0562, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 26/500 - Fold 1: Train Loss: 0.1498, Val Loss: 0.0566, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 27/500 - Fold 1: Train Loss: 0.1862, Val Loss: 0.0566, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 2
  Epoch 28/500 - Fold 1: Train Loss: 0.1733, Val Loss: 0.0568, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 3
  Epoch 29/500 - Fold 1: Train Loss: 0.1429, Val Loss: 0.0571, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 4
  Epoch 30/500 - Fold 1: Train Loss: 0.2126, Val Loss: 0.0570, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 5
  Epoch 31/500 - Fold 1: Train Loss: 0.1836, Val Loss: 0.0563, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 6
  Epoch 32/500 - Fold 1: Train Loss: 0.1513, Val Loss: 0.0554, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 33/500 - Fold 1: Train Loss: 0.1727, Val Loss: 0.0549, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 34/500 - Fold 1: Train Loss: 0.1118, Val Loss: 0.0546, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 35/500 - Fold 1: Train Loss: 0.1547, Val Loss: 0.0543, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 36/500 - Fold 1: Train Loss: 0.1272, Val Loss: 0.0541, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 37/500 - Fold 1: Train Loss: 0.2153, Val Loss: 0.0537, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 38/500 - Fold 1: Train Loss: 0.1017, Val Loss: 0.0535, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 39/500 - Fold 1: Train Loss: 0.1282, Val Loss: 0.0537, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 40/500 - Fold 1: Train Loss: 0.1533, Val Loss: 0.0532, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 41/500 - Fold 1: Train Loss: 0.1044, Val Loss: 0.0526, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 42/500 - Fold 1: Train Loss: 0.1884, Val Loss: 0.0522, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 43/500 - Fold 1: Train Loss: 0.1191, Val Loss: 0.0524, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 44/500 - Fold 1: Train Loss: 0.1436, Val Loss: 0.0524, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 2
  Epoch 45/500 - Fold 1: Train Loss: 0.1388, Val Loss: 0.0527, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 3
  Epoch 46/500 - Fold 1: Train Loss: 0.0842, Val Loss: 0.0530, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 4
  Epoch 47/500 - Fold 1: Train Loss: 0.1276, Val Loss: 0.0532, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 5
  Epoch 48/500 - Fold 1: Train Loss: 0.1594, Val Loss: 0.0537, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 6
  Epoch 49/500 - Fold 1: Train Loss: 0.1375, Val Loss: 0.0546, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 7
  Epoch 50/500 - Fold 1: Train Loss: 0.0579, Val Loss: 0.0553, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 8
  Epoch 51/500 - Fold 1: Train Loss: 0.1542, Val Loss: 0.0555, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 9
  Epoch 52/500 - Fold 1: Train Loss: 0.1442, Val Loss: 0.0560, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 10
  Early stopping triggered: Validation loss did not improve for 10 epochs.
  Fold 1 Training finished (or stopped early). Loading best model from validation...
  Fold 1 Final Validation Loss: 0.0560, Final Validation Accuracy: 1.0000
  Fold 1 Confusion Matrix:
[[3 0]
 [0 3]]

--- Fold 2/5 ---
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch_geometric\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
 Initializing optimizer and scheduler for Fold 2...
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch\optim\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
 Starting training and validation for Fold 2 with patience=10 epochs...
  Epoch 1/500 - Fold 2: Train Loss: 0.1825, Val Loss: 0.0476, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 2/500 - Fold 2: Train Loss: 0.1598, Val Loss: 0.0458, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 3/500 - Fold 2: Train Loss: 0.1045, Val Loss: 0.0444, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 4/500 - Fold 2: Train Loss: 0.1395, Val Loss: 0.0418, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 5/500 - Fold 2: Train Loss: 0.1515, Val Loss: 0.0394, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 6/500 - Fold 2: Train Loss: 0.1066, Val Loss: 0.0380, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 7/500 - Fold 2: Train Loss: 0.1235, Val Loss: 0.0355, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 8/500 - Fold 2: Train Loss: 0.1189, Val Loss: 0.0335, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 9/500 - Fold 2: Train Loss: 0.1641, Val Loss: 0.0328, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 10/500 - Fold 2: Train Loss: 0.0811, Val Loss: 0.0333, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 11/500 - Fold 2: Train Loss: 0.1282, Val Loss: 0.0334, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 2
  Epoch 12/500 - Fold 2: Train Loss: 0.1499, Val Loss: 0.0321, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 13/500 - Fold 2: Train Loss: 0.1021, Val Loss: 0.0301, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 14/500 - Fold 2: Train Loss: 0.0654, Val Loss: 0.0287, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 15/500 - Fold 2: Train Loss: 0.0947, Val Loss: 0.0262, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 16/500 - Fold 2: Train Loss: 0.1588, Val Loss: 0.0241, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 17/500 - Fold 2: Train Loss: 0.0999, Val Loss: 0.0225, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 18/500 - Fold 2: Train Loss: 0.1267, Val Loss: 0.0217, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 19/500 - Fold 2: Train Loss: 0.2238, Val Loss: 0.0217, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 20/500 - Fold 2: Train Loss: 0.1501, Val Loss: 0.0224, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 2
  Epoch 21/500 - Fold 2: Train Loss: 0.0769, Val Loss: 0.0244, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 3
  Epoch 22/500 - Fold 2: Train Loss: 0.1237, Val Loss: 0.0252, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 4
  Epoch 23/500 - Fold 2: Train Loss: 0.1709, Val Loss: 0.0247, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 5
  Epoch 24/500 - Fold 2: Train Loss: 0.1673, Val Loss: 0.0240, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 6
  Epoch 25/500 - Fold 2: Train Loss: 0.1584, Val Loss: 0.0229, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 7
  Epoch 26/500 - Fold 2: Train Loss: 0.0804, Val Loss: 0.0215, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 27/500 - Fold 2: Train Loss: 0.2080, Val Loss: 0.0200, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 28/500 - Fold 2: Train Loss: 0.0716, Val Loss: 0.0191, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 29/500 - Fold 2: Train Loss: 0.0877, Val Loss: 0.0186, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 30/500 - Fold 2: Train Loss: 0.1493, Val Loss: 0.0184, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 31/500 - Fold 2: Train Loss: 0.1257, Val Loss: 0.0182, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 32/500 - Fold 2: Train Loss: 0.0670, Val Loss: 0.0179, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 33/500 - Fold 2: Train Loss: 0.0984, Val Loss: 0.0178, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 34/500 - Fold 2: Train Loss: 0.1432, Val Loss: 0.0178, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 35/500 - Fold 2: Train Loss: 0.0944, Val Loss: 0.0179, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 2
  Epoch 36/500 - Fold 2: Train Loss: 0.1278, Val Loss: 0.0179, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 3
  Epoch 37/500 - Fold 2: Train Loss: 0.0897, Val Loss: 0.0178, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 38/500 - Fold 2: Train Loss: 0.0982, Val Loss: 0.0179, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 39/500 - Fold 2: Train Loss: 0.1315, Val Loss: 0.0181, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 2
  Epoch 40/500 - Fold 2: Train Loss: 0.1179, Val Loss: 0.0180, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 3
  Epoch 41/500 - Fold 2: Train Loss: 0.1220, Val Loss: 0.0185, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 4
  Epoch 42/500 - Fold 2: Train Loss: 0.1326, Val Loss: 0.0189, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 5
  Epoch 43/500 - Fold 2: Train Loss: 0.1325, Val Loss: 0.0192, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 6
  Epoch 44/500 - Fold 2: Train Loss: 0.1419, Val Loss: 0.0192, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 7
  Epoch 45/500 - Fold 2: Train Loss: 0.1694, Val Loss: 0.0197, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 8
  Epoch 46/500 - Fold 2: Train Loss: 0.0868, Val Loss: 0.0198, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 9
  Epoch 47/500 - Fold 2: Train Loss: 0.1073, Val Loss: 0.0200, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 10
  Early stopping triggered: Validation loss did not improve for 10 epochs.
  Fold 2 Training finished (or stopped early). Loading best model from validation...
  Fold 2 Final Validation Loss: 0.0200, Final Validation Accuracy: 1.0000
  Fold 2 Confusion Matrix:
[[2 0]
 [0 3]]

--- Fold 3/5 ---
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch_geometric\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
 Initializing optimizer and scheduler for Fold 3...
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch\optim\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
 Starting training and validation for Fold 3 with patience=10 epochs...
  Epoch 1/500 - Fold 3: Train Loss: 0.1586, Val Loss: 0.0305, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 2/500 - Fold 3: Train Loss: 0.0588, Val Loss: 0.0341, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 3/500 - Fold 3: Train Loss: 0.1337, Val Loss: 0.0323, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 2
  Epoch 4/500 - Fold 3: Train Loss: 0.1660, Val Loss: 0.0333, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 3
  Epoch 5/500 - Fold 3: Train Loss: 0.1362, Val Loss: 0.0344, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 4
  Epoch 6/500 - Fold 3: Train Loss: 0.1183, Val Loss: 0.0339, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 5
  Epoch 7/500 - Fold 3: Train Loss: 0.1168, Val Loss: 0.0351, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 6
  Epoch 8/500 - Fold 3: Train Loss: 0.1110, Val Loss: 0.0357, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 7
  Epoch 9/500 - Fold 3: Train Loss: 0.1121, Val Loss: 0.0359, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 8
  Epoch 10/500 - Fold 3: Train Loss: 0.1577, Val Loss: 0.0349, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 9
  Epoch 11/500 - Fold 3: Train Loss: 0.1011, Val Loss: 0.0356, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 10
  Early stopping triggered: Validation loss did not improve for 10 epochs.
  Fold 3 Training finished (or stopped early). Loading best model from validation...
  Fold 3 Final Validation Loss: 0.0356, Final Validation Accuracy: 1.0000
  Fold 3 Confusion Matrix:
[[3 0]
 [0 2]]

--- Fold 4/5 ---
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch_geometric\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
 Initializing optimizer and scheduler for Fold 4...
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch\optim\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
 Starting training and validation for Fold 4 with patience=10 epochs...
  Epoch 1/500 - Fold 4: Train Loss: 0.1601, Val Loss: 0.0252, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 2/500 - Fold 4: Train Loss: 0.1108, Val Loss: 0.0245, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 3/500 - Fold 4: Train Loss: 0.0956, Val Loss: 0.0254, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 4/500 - Fold 4: Train Loss: 0.1442, Val Loss: 0.0260, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 2
  Epoch 5/500 - Fold 4: Train Loss: 0.0685, Val Loss: 0.0261, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 3
  Epoch 6/500 - Fold 4: Train Loss: 0.1542, Val Loss: 0.0260, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 4
  Epoch 7/500 - Fold 4: Train Loss: 0.1062, Val Loss: 0.0257, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 5
  Epoch 8/500 - Fold 4: Train Loss: 0.0778, Val Loss: 0.0252, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 6
  Epoch 9/500 - Fold 4: Train Loss: 0.1731, Val Loss: 0.0245, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 10/500 - Fold 4: Train Loss: 0.1394, Val Loss: 0.0237, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 11/500 - Fold 4: Train Loss: 0.0707, Val Loss: 0.0230, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 12/500 - Fold 4: Train Loss: 0.1068, Val Loss: 0.0218, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 13/500 - Fold 4: Train Loss: 0.1308, Val Loss: 0.0212, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 14/500 - Fold 4: Train Loss: 0.1297, Val Loss: 0.0210, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 15/500 - Fold 4: Train Loss: 0.1227, Val Loss: 0.0211, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 16/500 - Fold 4: Train Loss: 0.0675, Val Loss: 0.0216, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 2
  Epoch 17/500 - Fold 4: Train Loss: 0.1124, Val Loss: 0.0224, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 3
  Epoch 18/500 - Fold 4: Train Loss: 0.1263, Val Loss: 0.0225, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 4
  Epoch 19/500 - Fold 4: Train Loss: 0.0807, Val Loss: 0.0226, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 5
  Epoch 20/500 - Fold 4: Train Loss: 0.1073, Val Loss: 0.0224, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 6
  Epoch 21/500 - Fold 4: Train Loss: 0.0748, Val Loss: 0.0213, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 7
  Epoch 22/500 - Fold 4: Train Loss: 0.1172, Val Loss: 0.0202, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 23/500 - Fold 4: Train Loss: 0.1331, Val Loss: 0.0192, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 24/500 - Fold 4: Train Loss: 0.1148, Val Loss: 0.0179, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 25/500 - Fold 4: Train Loss: 0.0873, Val Loss: 0.0166, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 26/500 - Fold 4: Train Loss: 0.0922, Val Loss: 0.0159, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 27/500 - Fold 4: Train Loss: 0.1284, Val Loss: 0.0151, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 28/500 - Fold 4: Train Loss: 0.1565, Val Loss: 0.0149, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 29/500 - Fold 4: Train Loss: 0.0815, Val Loss: 0.0146, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 30/500 - Fold 4: Train Loss: 0.0910, Val Loss: 0.0145, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 31/500 - Fold 4: Train Loss: 0.1008, Val Loss: 0.0146, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 32/500 - Fold 4: Train Loss: 0.1207, Val Loss: 0.0147, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 2
  Epoch 33/500 - Fold 4: Train Loss: 0.0861, Val Loss: 0.0149, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 3
  Epoch 34/500 - Fold 4: Train Loss: 0.1352, Val Loss: 0.0153, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 4
  Epoch 35/500 - Fold 4: Train Loss: 0.0916, Val Loss: 0.0161, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 5
  Epoch 36/500 - Fold 4: Train Loss: 0.1051, Val Loss: 0.0169, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 6
  Epoch 37/500 - Fold 4: Train Loss: 0.1697, Val Loss: 0.0174, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 7
  Epoch 38/500 - Fold 4: Train Loss: 0.1239, Val Loss: 0.0174, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 8
  Epoch 39/500 - Fold 4: Train Loss: 0.0618, Val Loss: 0.0173, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 9
  Epoch 40/500 - Fold 4: Train Loss: 0.0771, Val Loss: 0.0165, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 10
  Early stopping triggered: Validation loss did not improve for 10 epochs.
  Fold 4 Training finished (or stopped early). Loading best model from validation...
  Fold 4 Final Validation Loss: 0.0165, Final Validation Accuracy: 1.0000
  Fold 4 Confusion Matrix:
[[3 0]
 [0 2]]

--- Fold 5/5 ---
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch_geometric\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
 Initializing optimizer and scheduler for Fold 5...
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch\optim\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
 Starting training and validation for Fold 5 with patience=10 epochs...
  Epoch 1/500 - Fold 5: Train Loss: 0.0786, Val Loss: 0.0186, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 2/500 - Fold 5: Train Loss: 0.1293, Val Loss: 0.0176, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 3/500 - Fold 5: Train Loss: 0.0979, Val Loss: 0.0166, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 4/500 - Fold 5: Train Loss: 0.0988, Val Loss: 0.0160, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 5/500 - Fold 5: Train Loss: 0.1500, Val Loss: 0.0157, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 6/500 - Fold 5: Train Loss: 0.0586, Val Loss: 0.0155, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 7/500 - Fold 5: Train Loss: 0.0991, Val Loss: 0.0153, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 8/500 - Fold 5: Train Loss: 0.1259, Val Loss: 0.0148, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 9/500 - Fold 5: Train Loss: 0.0359, Val Loss: 0.0145, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 10/500 - Fold 5: Train Loss: 0.0952, Val Loss: 0.0145, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 11/500 - Fold 5: Train Loss: 0.0718, Val Loss: 0.0142, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 12/500 - Fold 5: Train Loss: 0.0789, Val Loss: 0.0141, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 13/500 - Fold 5: Train Loss: 0.0946, Val Loss: 0.0140, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 14/500 - Fold 5: Train Loss: 0.0807, Val Loss: 0.0138, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 15/500 - Fold 5: Train Loss: 0.1408, Val Loss: 0.0137, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 16/500 - Fold 5: Train Loss: 0.1572, Val Loss: 0.0138, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 17/500 - Fold 5: Train Loss: 0.1358, Val Loss: 0.0139, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 2
  Epoch 18/500 - Fold 5: Train Loss: 0.1585, Val Loss: 0.0143, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 3
  Epoch 19/500 - Fold 5: Train Loss: 0.1272, Val Loss: 0.0144, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 4
  Epoch 20/500 - Fold 5: Train Loss: 0.1178, Val Loss: 0.0143, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 5
  Epoch 21/500 - Fold 5: Train Loss: 0.0932, Val Loss: 0.0147, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 6
  Epoch 22/500 - Fold 5: Train Loss: 0.1573, Val Loss: 0.0149, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 7
  Epoch 23/500 - Fold 5: Train Loss: 0.0689, Val Loss: 0.0147, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 8
  Epoch 24/500 - Fold 5: Train Loss: 0.0809, Val Loss: 0.0147, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 9
  Epoch 25/500 - Fold 5: Train Loss: 0.0799, Val Loss: 0.0143, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 10
  Early stopping triggered: Validation loss did not improve for 10 epochs.
  Fold 5 Training finished (or stopped early). Loading best model from validation...
  Fold 5 Final Validation Loss: 0.0143, Final Validation Accuracy: 1.0000
  Fold 5 Confusion Matrix:
[[3 0]
 [0 2]]

--- Hyperparameter Combination: o_weight=0.5, co_weight=1.0 ---
Average Validation Accuracy: 0.9378 Â± 0.1299
Average Validation Loss: 0.2632

--- Fold 1/5 ---
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch_geometric\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
 Initializing optimizer and scheduler for Fold 1...
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch\optim\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
 Starting training and validation for Fold 1 with patience=10 epochs...
  Epoch 1/500 - Fold 1: Train Loss: 0.0908, Val Loss: 0.0134, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 2/500 - Fold 1: Train Loss: 0.0754, Val Loss: 0.0131, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 3/500 - Fold 1: Train Loss: 0.1370, Val Loss: 0.0135, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 4/500 - Fold 1: Train Loss: 0.1623, Val Loss: 0.0140, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 2
  Epoch 5/500 - Fold 1: Train Loss: 0.1361, Val Loss: 0.0146, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 3
  Epoch 6/500 - Fold 1: Train Loss: 0.0860, Val Loss: 0.0151, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 4
  Epoch 7/500 - Fold 1: Train Loss: 0.0607, Val Loss: 0.0151, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 5
  Epoch 8/500 - Fold 1: Train Loss: 0.0883, Val Loss: 0.0150, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 6
  Epoch 9/500 - Fold 1: Train Loss: 0.1021, Val Loss: 0.0150, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 7
  Epoch 10/500 - Fold 1: Train Loss: 0.1077, Val Loss: 0.0154, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 8
  Epoch 11/500 - Fold 1: Train Loss: 0.0972, Val Loss: 0.0158, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 9
  Epoch 12/500 - Fold 1: Train Loss: 0.1669, Val Loss: 0.0160, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 10
  Early stopping triggered: Validation loss did not improve for 10 epochs.
  Fold 1 Training finished (or stopped early). Loading best model from validation...
  Fold 1 Final Validation Loss: 0.0160, Final Validation Accuracy: 1.0000
  Fold 1 Confusion Matrix:
[[3 0]
 [0 3]]

--- Fold 2/5 ---
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch_geometric\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
 Initializing optimizer and scheduler for Fold 2...
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch\optim\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
 Starting training and validation for Fold 2 with patience=10 epochs...
  Epoch 1/500 - Fold 2: Train Loss: 0.0921, Val Loss: 0.0185, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 2/500 - Fold 2: Train Loss: 0.1486, Val Loss: 0.0162, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 3/500 - Fold 2: Train Loss: 0.0953, Val Loss: 0.0140, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 4/500 - Fold 2: Train Loss: 0.1016, Val Loss: 0.0132, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 5/500 - Fold 2: Train Loss: 0.0524, Val Loss: 0.0142, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 6/500 - Fold 2: Train Loss: 0.0961, Val Loss: 0.0171, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 2
  Epoch 7/500 - Fold 2: Train Loss: 0.1075, Val Loss: 0.0219, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 3
  Epoch 8/500 - Fold 2: Train Loss: 0.0871, Val Loss: 0.0272, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 4
  Epoch 9/500 - Fold 2: Train Loss: 0.1324, Val Loss: 0.0334, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 5
  Epoch 10/500 - Fold 2: Train Loss: 0.0853, Val Loss: 0.0329, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 6
  Epoch 11/500 - Fold 2: Train Loss: 0.0435, Val Loss: 0.0273, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 7
  Epoch 12/500 - Fold 2: Train Loss: 0.0729, Val Loss: 0.0197, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 8
  Epoch 13/500 - Fold 2: Train Loss: 0.0888, Val Loss: 0.0142, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 9
  Epoch 14/500 - Fold 2: Train Loss: 0.0831, Val Loss: 0.0111, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 15/500 - Fold 2: Train Loss: 0.1019, Val Loss: 0.0097, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 16/500 - Fold 2: Train Loss: 0.0705, Val Loss: 0.0096, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 17/500 - Fold 2: Train Loss: 0.0640, Val Loss: 0.0105, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 18/500 - Fold 2: Train Loss: 0.0827, Val Loss: 0.0117, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 2
  Epoch 19/500 - Fold 2: Train Loss: 0.1353, Val Loss: 0.0134, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 3
  Epoch 20/500 - Fold 2: Train Loss: 0.1368, Val Loss: 0.0139, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 4
  Epoch 21/500 - Fold 2: Train Loss: 0.0675, Val Loss: 0.0134, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 5
  Epoch 22/500 - Fold 2: Train Loss: 0.0510, Val Loss: 0.0125, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 6
  Epoch 23/500 - Fold 2: Train Loss: 0.1218, Val Loss: 0.0117, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 7
  Epoch 24/500 - Fold 2: Train Loss: 0.0670, Val Loss: 0.0103, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 8
  Epoch 25/500 - Fold 2: Train Loss: 0.0621, Val Loss: 0.0094, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 26/500 - Fold 2: Train Loss: 0.0959, Val Loss: 0.0084, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 27/500 - Fold 2: Train Loss: 0.0929, Val Loss: 0.0079, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 28/500 - Fold 2: Train Loss: 0.0592, Val Loss: 0.0078, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 29/500 - Fold 2: Train Loss: 0.1090, Val Loss: 0.0079, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 30/500 - Fold 2: Train Loss: 0.0783, Val Loss: 0.0080, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 2
  Epoch 31/500 - Fold 2: Train Loss: 0.0978, Val Loss: 0.0081, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 3
  Epoch 32/500 - Fold 2: Train Loss: 0.0613, Val Loss: 0.0080, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 4
  Epoch 33/500 - Fold 2: Train Loss: 0.0694, Val Loss: 0.0078, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 5
  Epoch 34/500 - Fold 2: Train Loss: 0.1335, Val Loss: 0.0077, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 35/500 - Fold 2: Train Loss: 0.0811, Val Loss: 0.0074, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 36/500 - Fold 2: Train Loss: 0.0431, Val Loss: 0.0071, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 37/500 - Fold 2: Train Loss: 0.0792, Val Loss: 0.0070, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 38/500 - Fold 2: Train Loss: 0.0444, Val Loss: 0.0069, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 39/500 - Fold 2: Train Loss: 0.0745, Val Loss: 0.0069, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 40/500 - Fold 2: Train Loss: 0.0599, Val Loss: 0.0070, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 41/500 - Fold 2: Train Loss: 0.0782, Val Loss: 0.0071, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 2
  Epoch 42/500 - Fold 2: Train Loss: 0.0953, Val Loss: 0.0071, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 3
  Epoch 43/500 - Fold 2: Train Loss: 0.0720, Val Loss: 0.0074, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 4
  Epoch 44/500 - Fold 2: Train Loss: 0.1074, Val Loss: 0.0074, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 5
  Epoch 45/500 - Fold 2: Train Loss: 0.0536, Val Loss: 0.0075, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 6
  Epoch 46/500 - Fold 2: Train Loss: 0.0962, Val Loss: 0.0074, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 7
  Epoch 47/500 - Fold 2: Train Loss: 0.0427, Val Loss: 0.0074, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 8
  Epoch 48/500 - Fold 2: Train Loss: 0.0835, Val Loss: 0.0074, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 9
  Epoch 49/500 - Fold 2: Train Loss: 0.0782, Val Loss: 0.0073, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 10
  Early stopping triggered: Validation loss did not improve for 10 epochs.
  Fold 2 Training finished (or stopped early). Loading best model from validation...
  Fold 2 Final Validation Loss: 0.0073, Final Validation Accuracy: 1.0000
  Fold 2 Confusion Matrix:
[[2 0]
 [0 3]]

--- Fold 3/5 ---
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch_geometric\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
 Initializing optimizer and scheduler for Fold 3...
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch\optim\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
 Starting training and validation for Fold 3 with patience=10 epochs...
  Epoch 1/500 - Fold 3: Train Loss: 0.0458, Val Loss: 0.0097, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 2/500 - Fold 3: Train Loss: 0.0850, Val Loss: 0.0088, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 3/500 - Fold 3: Train Loss: 0.0802, Val Loss: 0.0084, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 4/500 - Fold 3: Train Loss: 0.1018, Val Loss: 0.0082, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 5/500 - Fold 3: Train Loss: 0.0644, Val Loss: 0.0083, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 6/500 - Fold 3: Train Loss: 0.2149, Val Loss: 0.0090, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 2
  Epoch 7/500 - Fold 3: Train Loss: 0.0763, Val Loss: 0.0101, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 3
  Epoch 8/500 - Fold 3: Train Loss: 0.0840, Val Loss: 0.0118, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 4
  Epoch 9/500 - Fold 3: Train Loss: 0.0562, Val Loss: 0.0128, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 5
  Epoch 10/500 - Fold 3: Train Loss: 0.0613, Val Loss: 0.0138, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 6
  Epoch 11/500 - Fold 3: Train Loss: 0.1561, Val Loss: 0.0151, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 7
  Epoch 12/500 - Fold 3: Train Loss: 0.0866, Val Loss: 0.0170, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 8
  Epoch 13/500 - Fold 3: Train Loss: 0.1463, Val Loss: 0.0178, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 9
  Epoch 14/500 - Fold 3: Train Loss: 0.0801, Val Loss: 0.0184, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 10
  Early stopping triggered: Validation loss did not improve for 10 epochs.
  Fold 3 Training finished (or stopped early). Loading best model from validation...
  Fold 3 Final Validation Loss: 0.0184, Final Validation Accuracy: 1.0000
  Fold 3 Confusion Matrix:
[[3 0]
 [0 2]]

--- Fold 4/5 ---
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch_geometric\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
 Initializing optimizer and scheduler for Fold 4...
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch\optim\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
 Starting training and validation for Fold 4 with patience=10 epochs...
  Epoch 1/500 - Fold 4: Train Loss: 0.0752, Val Loss: 0.0099, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 2/500 - Fold 4: Train Loss: 0.0535, Val Loss: 0.0098, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 3/500 - Fold 4: Train Loss: 0.0695, Val Loss: 0.0100, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 4/500 - Fold 4: Train Loss: 0.0575, Val Loss: 0.0099, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 2
  Epoch 5/500 - Fold 4: Train Loss: 0.1047, Val Loss: 0.0099, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 3
  Epoch 6/500 - Fold 4: Train Loss: 0.0605, Val Loss: 0.0095, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 7/500 - Fold 4: Train Loss: 0.1118, Val Loss: 0.0094, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 8/500 - Fold 4: Train Loss: 0.0701, Val Loss: 0.0092, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 9/500 - Fold 4: Train Loss: 0.0644, Val Loss: 0.0090, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 10/500 - Fold 4: Train Loss: 0.0520, Val Loss: 0.0085, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 11/500 - Fold 4: Train Loss: 0.0480, Val Loss: 0.0082, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 12/500 - Fold 4: Train Loss: 0.0978, Val Loss: 0.0077, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 13/500 - Fold 4: Train Loss: 0.0410, Val Loss: 0.0071, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 14/500 - Fold 4: Train Loss: 0.0887, Val Loss: 0.0066, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 15/500 - Fold 4: Train Loss: 0.0575, Val Loss: 0.0061, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 16/500 - Fold 4: Train Loss: 0.0705, Val Loss: 0.0058, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 17/500 - Fold 4: Train Loss: 0.1073, Val Loss: 0.0055, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 18/500 - Fold 4: Train Loss: 0.0544, Val Loss: 0.0052, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 19/500 - Fold 4: Train Loss: 0.0842, Val Loss: 0.0050, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 20/500 - Fold 4: Train Loss: 0.0665, Val Loss: 0.0049, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 21/500 - Fold 4: Train Loss: 0.1417, Val Loss: 0.0050, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 22/500 - Fold 4: Train Loss: 0.0735, Val Loss: 0.0050, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 2
  Epoch 23/500 - Fold 4: Train Loss: 0.0728, Val Loss: 0.0053, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 3
  Epoch 24/500 - Fold 4: Train Loss: 0.0788, Val Loss: 0.0058, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 4
  Epoch 25/500 - Fold 4: Train Loss: 0.0701, Val Loss: 0.0059, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 5
  Epoch 26/500 - Fold 4: Train Loss: 0.0559, Val Loss: 0.0061, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 6
  Epoch 27/500 - Fold 4: Train Loss: 0.0719, Val Loss: 0.0061, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 7
  Epoch 28/500 - Fold 4: Train Loss: 0.0725, Val Loss: 0.0062, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 8
  Epoch 29/500 - Fold 4: Train Loss: 0.0548, Val Loss: 0.0063, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 9
  Epoch 30/500 - Fold 4: Train Loss: 0.0803, Val Loss: 0.0062, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 10
  Early stopping triggered: Validation loss did not improve for 10 epochs.
  Fold 4 Training finished (or stopped early). Loading best model from validation...
  Fold 4 Final Validation Loss: 0.0062, Final Validation Accuracy: 1.0000
  Fold 4 Confusion Matrix:
[[3 0]
 [0 2]]

--- Fold 5/5 ---
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch_geometric\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
 Initializing optimizer and scheduler for Fold 5...
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch\optim\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
 Starting training and validation for Fold 5 with patience=10 epochs...
  Epoch 1/500 - Fold 5: Train Loss: 0.0519, Val Loss: 0.0075, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 2/500 - Fold 5: Train Loss: 0.0463, Val Loss: 0.0095, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 3/500 - Fold 5: Train Loss: 0.0676, Val Loss: 0.0105, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 2
  Epoch 4/500 - Fold 5: Train Loss: 0.0634, Val Loss: 0.0114, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 3
  Epoch 5/500 - Fold 5: Train Loss: 0.0573, Val Loss: 0.0112, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 4
  Epoch 6/500 - Fold 5: Train Loss: 0.0709, Val Loss: 0.0109, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 5
  Epoch 7/500 - Fold 5: Train Loss: 0.1032, Val Loss: 0.0101, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 6
  Epoch 8/500 - Fold 5: Train Loss: 0.1023, Val Loss: 0.0094, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 7
  Epoch 9/500 - Fold 5: Train Loss: 0.1459, Val Loss: 0.0089, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 8
  Epoch 10/500 - Fold 5: Train Loss: 0.0637, Val Loss: 0.0085, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 9
  Epoch 11/500 - Fold 5: Train Loss: 0.0676, Val Loss: 0.0081, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 10
  Early stopping triggered: Validation loss did not improve for 10 epochs.
  Fold 5 Training finished (or stopped early). Loading best model from validation...
  Fold 5 Final Validation Loss: 0.0081, Final Validation Accuracy: 1.0000
  Fold 5 Confusion Matrix:
[[3 0]
 [0 2]]

--- Hyperparameter Combination: o_weight=0.5, co_weight=1.0 ---
Average Validation Accuracy: 0.9533 Â± 0.1157
Average Validation Loss: 0.2002

--- Fold 1/5 ---
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch_geometric\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
 Initializing optimizer and scheduler for Fold 1...
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch\optim\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
 Starting training and validation for Fold 1 with patience=10 epochs...
  Epoch 1/500 - Fold 1: Train Loss: 0.0713, Val Loss: 0.0088, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 2/500 - Fold 1: Train Loss: 0.0944, Val Loss: 0.0103, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 3/500 - Fold 1: Train Loss: 0.1092, Val Loss: 0.0114, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 2
  Epoch 4/500 - Fold 1: Train Loss: 0.1214, Val Loss: 0.0106, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 3
  Epoch 5/500 - Fold 1: Train Loss: 0.0672, Val Loss: 0.0089, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 4
  Epoch 6/500 - Fold 1: Train Loss: 0.0914, Val Loss: 0.0079, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 7/500 - Fold 1: Train Loss: 0.1260, Val Loss: 0.0077, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 8/500 - Fold 1: Train Loss: 0.0614, Val Loss: 0.0078, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 9/500 - Fold 1: Train Loss: 0.0846, Val Loss: 0.0081, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 2
  Epoch 10/500 - Fold 1: Train Loss: 0.1128, Val Loss: 0.0085, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 3
  Epoch 11/500 - Fold 1: Train Loss: 0.0474, Val Loss: 0.0088, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 4
  Epoch 12/500 - Fold 1: Train Loss: 0.0290, Val Loss: 0.0087, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 5
  Epoch 13/500 - Fold 1: Train Loss: 0.0756, Val Loss: 0.0086, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 6
  Epoch 14/500 - Fold 1: Train Loss: 0.1035, Val Loss: 0.0082, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 7
  Epoch 15/500 - Fold 1: Train Loss: 0.0420, Val Loss: 0.0079, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 8
  Epoch 16/500 - Fold 1: Train Loss: 0.1094, Val Loss: 0.0077, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 9
  Epoch 17/500 - Fold 1: Train Loss: 0.1295, Val Loss: 0.0075, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 18/500 - Fold 1: Train Loss: 0.1519, Val Loss: 0.0074, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 19/500 - Fold 1: Train Loss: 0.0726, Val Loss: 0.0072, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 20/500 - Fold 1: Train Loss: 0.1323, Val Loss: 0.0071, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 21/500 - Fold 1: Train Loss: 0.0957, Val Loss: 0.0069, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 22/500 - Fold 1: Train Loss: 0.0450, Val Loss: 0.0069, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 23/500 - Fold 1: Train Loss: 0.1139, Val Loss: 0.0069, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 24/500 - Fold 1: Train Loss: 0.1143, Val Loss: 0.0070, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 2
  Epoch 25/500 - Fold 1: Train Loss: 0.0458, Val Loss: 0.0070, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 3
  Epoch 26/500 - Fold 1: Train Loss: 0.0421, Val Loss: 0.0070, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 4
  Epoch 27/500 - Fold 1: Train Loss: 0.0997, Val Loss: 0.0071, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 5
  Epoch 28/500 - Fold 1: Train Loss: 0.0437, Val Loss: 0.0072, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 6
  Epoch 29/500 - Fold 1: Train Loss: 0.0670, Val Loss: 0.0071, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 7
  Epoch 30/500 - Fold 1: Train Loss: 0.0882, Val Loss: 0.0070, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 8
  Epoch 31/500 - Fold 1: Train Loss: 0.0375, Val Loss: 0.0071, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 9
  Epoch 32/500 - Fold 1: Train Loss: 0.0363, Val Loss: 0.0072, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 10
  Early stopping triggered: Validation loss did not improve for 10 epochs.
  Fold 1 Training finished (or stopped early). Loading best model from validation...
  Fold 1 Final Validation Loss: 0.0072, Final Validation Accuracy: 1.0000
  Fold 1 Confusion Matrix:
[[3 0]
 [0 3]]

--- Fold 2/5 ---
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch_geometric\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
 Initializing optimizer and scheduler for Fold 2...
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch\optim\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
 Starting training and validation for Fold 2 with patience=10 epochs...
  Epoch 1/500 - Fold 2: Train Loss: 0.0552, Val Loss: 0.0080, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 2/500 - Fold 2: Train Loss: 0.0751, Val Loss: 0.0083, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 3/500 - Fold 2: Train Loss: 0.0623, Val Loss: 0.0084, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 2
  Epoch 4/500 - Fold 2: Train Loss: 0.0522, Val Loss: 0.0081, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 3
  Epoch 5/500 - Fold 2: Train Loss: 0.0553, Val Loss: 0.0086, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 4
  Epoch 6/500 - Fold 2: Train Loss: 0.0574, Val Loss: 0.0097, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 5
  Epoch 7/500 - Fold 2: Train Loss: 0.0298, Val Loss: 0.0123, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 6
  Epoch 8/500 - Fold 2: Train Loss: 0.0388, Val Loss: 0.0152, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 7
  Epoch 9/500 - Fold 2: Train Loss: 0.0318, Val Loss: 0.0183, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 8
  Epoch 10/500 - Fold 2: Train Loss: 0.0491, Val Loss: 0.0269, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 9
  Epoch 11/500 - Fold 2: Train Loss: 0.0780, Val Loss: 0.0363, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 10
  Early stopping triggered: Validation loss did not improve for 10 epochs.
  Fold 2 Training finished (or stopped early). Loading best model from validation...
  Fold 2 Final Validation Loss: 0.0363, Final Validation Accuracy: 1.0000
  Fold 2 Confusion Matrix:
[[2 0]
 [0 3]]

--- Fold 3/5 ---
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch_geometric\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
 Initializing optimizer and scheduler for Fold 3...
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch\optim\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
 Starting training and validation for Fold 3 with patience=10 epochs...
  Epoch 1/500 - Fold 3: Train Loss: 0.0834, Val Loss: 0.0079, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 2/500 - Fold 3: Train Loss: 0.0305, Val Loss: 0.0053, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 3/500 - Fold 3: Train Loss: 0.1523, Val Loss: 0.0048, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 4/500 - Fold 3: Train Loss: 0.0529, Val Loss: 0.0049, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 5/500 - Fold 3: Train Loss: 0.0514, Val Loss: 0.0047, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 6/500 - Fold 3: Train Loss: 0.1237, Val Loss: 0.0048, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 7/500 - Fold 3: Train Loss: 0.0417, Val Loss: 0.0049, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 2
  Epoch 8/500 - Fold 3: Train Loss: 0.0602, Val Loss: 0.0049, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 3
  Epoch 9/500 - Fold 3: Train Loss: 0.0382, Val Loss: 0.0049, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 4
  Epoch 10/500 - Fold 3: Train Loss: 0.0324, Val Loss: 0.0051, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 5
  Epoch 11/500 - Fold 3: Train Loss: 0.0285, Val Loss: 0.0053, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 6
  Epoch 12/500 - Fold 3: Train Loss: 0.0841, Val Loss: 0.0054, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 7
  Epoch 13/500 - Fold 3: Train Loss: 0.1060, Val Loss: 0.0056, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 8
  Epoch 14/500 - Fold 3: Train Loss: 0.0869, Val Loss: 0.0057, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 9
  Epoch 15/500 - Fold 3: Train Loss: 0.0182, Val Loss: 0.0057, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 10
  Early stopping triggered: Validation loss did not improve for 10 epochs.
  Fold 3 Training finished (or stopped early). Loading best model from validation...
  Fold 3 Final Validation Loss: 0.0057, Final Validation Accuracy: 1.0000
  Fold 3 Confusion Matrix:
[[3 0]
 [0 2]]

--- Fold 4/5 ---
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch_geometric\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
 Initializing optimizer and scheduler for Fold 4...
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch\optim\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
 Starting training and validation for Fold 4 with patience=10 epochs...
  Epoch 1/500 - Fold 4: Train Loss: 0.0498, Val Loss: 0.0071, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 2/500 - Fold 4: Train Loss: 0.0403, Val Loss: 0.0068, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 3/500 - Fold 4: Train Loss: 0.0819, Val Loss: 0.0069, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 4/500 - Fold 4: Train Loss: 0.0264, Val Loss: 0.0070, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 2
  Epoch 5/500 - Fold 4: Train Loss: 0.0788, Val Loss: 0.0066, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 6/500 - Fold 4: Train Loss: 0.0780, Val Loss: 0.0061, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 7/500 - Fold 4: Train Loss: 0.0766, Val Loss: 0.0056, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 8/500 - Fold 4: Train Loss: 0.0589, Val Loss: 0.0053, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 9/500 - Fold 4: Train Loss: 0.0828, Val Loss: 0.0054, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 10/500 - Fold 4: Train Loss: 0.0998, Val Loss: 0.0056, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 2
  Epoch 11/500 - Fold 4: Train Loss: 0.0504, Val Loss: 0.0056, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 3
  Epoch 12/500 - Fold 4: Train Loss: 0.0399, Val Loss: 0.0053, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 13/500 - Fold 4: Train Loss: 0.0860, Val Loss: 0.0050, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 14/500 - Fold 4: Train Loss: 0.0540, Val Loss: 0.0049, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 15/500 - Fold 4: Train Loss: 0.0607, Val Loss: 0.0049, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 16/500 - Fold 4: Train Loss: 0.0581, Val Loss: 0.0049, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 17/500 - Fold 4: Train Loss: 0.0460, Val Loss: 0.0049, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 2
  Epoch 18/500 - Fold 4: Train Loss: 0.0437, Val Loss: 0.0046, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 19/500 - Fold 4: Train Loss: 0.0206, Val Loss: 0.0044, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 20/500 - Fold 4: Train Loss: 0.0565, Val Loss: 0.0041, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 21/500 - Fold 4: Train Loss: 0.0585, Val Loss: 0.0040, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 22/500 - Fold 4: Train Loss: 0.0508, Val Loss: 0.0038, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 23/500 - Fold 4: Train Loss: 0.1552, Val Loss: 0.0039, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 24/500 - Fold 4: Train Loss: 0.0780, Val Loss: 0.0039, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 2
  Epoch 25/500 - Fold 4: Train Loss: 0.0559, Val Loss: 0.0041, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 3
  Epoch 26/500 - Fold 4: Train Loss: 0.0408, Val Loss: 0.0044, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 4
  Epoch 27/500 - Fold 4: Train Loss: 0.0978, Val Loss: 0.0046, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 5
  Epoch 28/500 - Fold 4: Train Loss: 0.0874, Val Loss: 0.0048, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 6
  Epoch 29/500 - Fold 4: Train Loss: 0.0432, Val Loss: 0.0049, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 7
  Epoch 30/500 - Fold 4: Train Loss: 0.0765, Val Loss: 0.0048, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 8
  Epoch 31/500 - Fold 4: Train Loss: 0.0390, Val Loss: 0.0046, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 9
  Epoch 32/500 - Fold 4: Train Loss: 0.0511, Val Loss: 0.0045, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 10
  Early stopping triggered: Validation loss did not improve for 10 epochs.
  Fold 4 Training finished (or stopped early). Loading best model from validation...
  Fold 4 Final Validation Loss: 0.0045, Final Validation Accuracy: 1.0000
  Fold 4 Confusion Matrix:
[[3 0]
 [0 2]]

--- Fold 5/5 ---
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch_geometric\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
 Initializing optimizer and scheduler for Fold 5...
C:\Users\bqtha\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch\optim\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
 Starting training and validation for Fold 5 with patience=10 epochs...
  Epoch 1/500 - Fold 5: Train Loss: 0.0593, Val Loss: 0.0061, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 2/500 - Fold 5: Train Loss: 0.0777, Val Loss: 0.0058, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 3/500 - Fold 5: Train Loss: 0.0507, Val Loss: 0.0054, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 4/500 - Fold 5: Train Loss: 0.1425, Val Loss: 0.0054, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 0
  Epoch 5/500 - Fold 5: Train Loss: 0.0766, Val Loss: 0.0055, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 1
  Epoch 6/500 - Fold 5: Train Loss: 0.1107, Val Loss: 0.0056, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 2
  Epoch 7/500 - Fold 5: Train Loss: 0.1218, Val Loss: 0.0057, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 3
  Epoch 8/500 - Fold 5: Train Loss: 0.0192, Val Loss: 0.0057, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 4
  Epoch 9/500 - Fold 5: Train Loss: 0.0405, Val Loss: 0.0058, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 5
  Epoch 10/500 - Fold 5: Train Loss: 0.0366, Val Loss: 0.0059, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 6
  Epoch 11/500 - Fold 5: Train Loss: 0.0219, Val Loss: 0.0059, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 7
  Epoch 12/500 - Fold 5: Train Loss: 0.0520, Val Loss: 0.0061, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 8
  Epoch 13/500 - Fold 5: Train Loss: 0.0588, Val Loss: 0.0063, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 9
  Epoch 14/500 - Fold 5: Train Loss: 0.0422, Val Loss: 0.0062, Val Acc: 1.0000, Best Val Acc: 1.0000, No Improvement Epochs: 10
  Early stopping triggered: Validation loss did not improve for 10 epochs.
  Fold 5 Training finished (or stopped early). Loading best model from validation...
  Fold 5 Final Validation Loss: 0.0062, Final Validation Accuracy: 1.0000
  Fold 5 Confusion Matrix:
[[3 0]
 [0 2]]

--- Hyperparameter Combination: o_weight=0.5, co_weight=1.0 ---
Average Validation Accuracy: 0.9627 Â± 0.1051
Average Validation Loss: 0.1625

--- Hyperparameter Tuning Complete ---
Best Hyperparameters:
  o_weight: 0.5
  co_weight: 1.0
Best Average Validation Accuracy: 0.9627

--- All Hyperparameter Tuning Results ---

Hyperparameters: o_weight=0.5, co_weight=1.0
  Average Validation Accuracy: 0.9627 Â± 0.1051
  Average Validation Loss: 0.1625
  Fold Validation Accuracies: [0.6666666666666666, 0.6, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]